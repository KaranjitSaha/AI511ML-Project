{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing important libraries and reading the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt \n",
    "train_df = pd.read_csv(\"train_df.csv\")\n",
    "test_df = pd.read_csv(\"test_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for null values, invalid target values and duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dda0b0efc8ba86e81ec4</td>\n",
       "      <td>What are interesting facts about Microsoft his...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dc708b74a108d0fc0ad9</td>\n",
       "      <td>What are those things which are not gonna happ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06a27ec5d82dacd8bfe0</td>\n",
       "      <td>What should I know to avoid being \"upsold\" whe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00cbb6b17e3ceb7c5358</td>\n",
       "      <td>How I add any account with payment bank?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c304888973a701585a0</td>\n",
       "      <td>Which Multi level marketing products are actua...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>4bd96088d0b5f0f2c4f4</td>\n",
       "      <td>How is CSE at VIT Chennai?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>e80edbfc086f7125940f</td>\n",
       "      <td>How can we prevent a holocaust by robots, AI, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>1506dfad6bd340782a1f</td>\n",
       "      <td>How can I help a student remember key steps an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>b56c60fd407f2f85553c</td>\n",
       "      <td>What is the difference between lace closure &amp; ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>a1b32d315c2782cdbcc3</td>\n",
       "      <td>What happens when you look into a broken mirror?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "0       dda0b0efc8ba86e81ec4   \n",
       "1       dc708b74a108d0fc0ad9   \n",
       "2       06a27ec5d82dacd8bfe0   \n",
       "3       00cbb6b17e3ceb7c5358   \n",
       "4       7c304888973a701585a0   \n",
       "...                      ...   \n",
       "999995  4bd96088d0b5f0f2c4f4   \n",
       "999996  e80edbfc086f7125940f   \n",
       "999997  1506dfad6bd340782a1f   \n",
       "999998  b56c60fd407f2f85553c   \n",
       "999999  a1b32d315c2782cdbcc3   \n",
       "\n",
       "                                            question_text  target  \n",
       "0       What are interesting facts about Microsoft his...       0  \n",
       "1       What are those things which are not gonna happ...       0  \n",
       "2       What should I know to avoid being \"upsold\" whe...       0  \n",
       "3                How I add any account with payment bank?       0  \n",
       "4       Which Multi level marketing products are actua...       0  \n",
       "...                                                   ...     ...  \n",
       "999995                         How is CSE at VIT Chennai?       0  \n",
       "999996  How can we prevent a holocaust by robots, AI, ...       0  \n",
       "999997  How can I help a student remember key steps an...       0  \n",
       "999998  What is the difference between lace closure & ...       0  \n",
       "999999   What happens when you look into a broken mirror?       0  \n",
       "\n",
       "[1000000 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.061870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.240919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               target\n",
       "count  1000000.000000\n",
       "mean         0.061870\n",
       "std          0.240919\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          1.000000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid              0\n",
       "question_text    0\n",
       "target           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"target\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.index[train_df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for null values and duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a4f3da3a3df9dd881edd</td>\n",
       "      <td>My period is due on my wedding day. How can I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9914c62ed3f69684d549</td>\n",
       "      <td>How many numbers higher than a million can be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8138ae48649e37091a91</td>\n",
       "      <td>How come I feel nothing for my family, but sti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>981b4753d17ef14d09f7</td>\n",
       "      <td>In case of collapse of the Democratic party, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>452e2c705276ba16b7b7</td>\n",
       "      <td>Who is Émile Naoumoff?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306117</th>\n",
       "      <td>a352dff4fcc2571815ce</td>\n",
       "      <td>Did anyone get an update on Maruti Suzuki All ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306118</th>\n",
       "      <td>ad4a8498d97c536c67b9</td>\n",
       "      <td>What 5 people in history do you find the most ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306119</th>\n",
       "      <td>19784a27b55d4b453fda</td>\n",
       "      <td>How can I remove the tan on my forehead?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306120</th>\n",
       "      <td>370191dba26465997879</td>\n",
       "      <td>If you are a well known hacker, will you be mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306121</th>\n",
       "      <td>8077b4a45cea867d4ff2</td>\n",
       "      <td>If your new enemies be bigger and more dangero...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306122 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "0       a4f3da3a3df9dd881edd   \n",
       "1       9914c62ed3f69684d549   \n",
       "2       8138ae48649e37091a91   \n",
       "3       981b4753d17ef14d09f7   \n",
       "4       452e2c705276ba16b7b7   \n",
       "...                      ...   \n",
       "306117  a352dff4fcc2571815ce   \n",
       "306118  ad4a8498d97c536c67b9   \n",
       "306119  19784a27b55d4b453fda   \n",
       "306120  370191dba26465997879   \n",
       "306121  8077b4a45cea867d4ff2   \n",
       "\n",
       "                                            question_text  \n",
       "0       My period is due on my wedding day. How can I ...  \n",
       "1       How many numbers higher than a million can be ...  \n",
       "2       How come I feel nothing for my family, but sti...  \n",
       "3       In case of collapse of the Democratic party, w...  \n",
       "4                                  Who is Émile Naoumoff?  \n",
       "...                                                   ...  \n",
       "306117  Did anyone get an update on Maruti Suzuki All ...  \n",
       "306118  What 5 people in history do you find the most ...  \n",
       "306119           How can I remove the tan on my forehead?  \n",
       "306120  If you are a well known hacker, will you be mo...  \n",
       "306121  If your new enemies be bigger and more dangero...  \n",
       "\n",
       "[306122 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid              0\n",
       "question_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.index[test_df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the text\n",
    "When dealing with numerical data, data cleaning often involves removing null values and duplicate data, dealing with outliers, etc. With text data, there are some common data cleaning techniques, which are also known as text pre-processing techniques.\n",
    "\n",
    "With text data, this cleaning process can go on forever. There's always an exception to every cleaning step. So, we're going to follow the MVP (minimum viable product) approach - start simple and iterate. Here are a bunch of things you can do to clean your data. We're going to execute just the common cleaning steps here and the rest can be done at a later point to improve our results.\n",
    "\n",
    "Common data cleaning steps on all text:\n",
    "\n",
    "Make text all lower case\n",
    "Remove punctuation\n",
    "Remove numerical values\n",
    "Remove common non-sensical text (/n)\n",
    "Tokenize text\n",
    "Remove stop words\n",
    "More data cleaning steps after tokenization:\n",
    "\n",
    "Stemming / lemmatization\n",
    "Parts of speech tagging\n",
    "Create bi-grams or tri-grams\n",
    "Deal with typos\n",
    "And more..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here (in round 1) we are doing the following things:-\n",
    "1. Making the text lower case.\n",
    "2. Removing text in square brackets\n",
    "3. Removing punctuation marks from the text\n",
    "4. Removing words containing numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text_round1(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "round1 = lambda x: clean_text_round1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         what are interesting facts about microsoft his...\n",
       "1         what are those things which are not gonna happ...\n",
       "2         what should i know to avoid being upsold when ...\n",
       "3                   how i add any account with payment bank\n",
       "4         which multi level marketing products are actua...\n",
       "                                ...                        \n",
       "999995                            how is cse at vit chennai\n",
       "999996    how can we prevent a holocaust by robots ai or...\n",
       "999997    how can i help a student remember key steps an...\n",
       "999998    what is the difference between lace closure  l...\n",
       "999999      what happens when you look into a broken mirror\n",
       "Name: question_text, Length: 1000000, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.question_text= train_df.question_text.apply(round1)\n",
    "train_df.question_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here (in round2) we are doing:-\n",
    "1. Getting rid of additional punctuation\n",
    "2. Removing some non-sensical text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a second round of cleaning\n",
    "def clean_text_round2(text):\n",
    "    '''Get rid of some additional punctuation and non-sensical text that was missed the first time around.'''\n",
    "    text = re.sub('[‘’“”…]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    return text\n",
    "round2 = lambda x: clean_text_round2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         what are interesting facts about microsoft his...\n",
       "1         what are those things which are not gonna happ...\n",
       "2         what should i know to avoid being upsold when ...\n",
       "3                   how i add any account with payment bank\n",
       "4         which multi level marketing products are actua...\n",
       "                                ...                        \n",
       "999995                            how is cse at vit chennai\n",
       "999996    how can we prevent a holocaust by robots ai or...\n",
       "999997    how can i help a student remember key steps an...\n",
       "999998    what is the difference between lace closure  l...\n",
       "999999      what happens when you look into a broken mirror\n",
       "Name: question_text, Length: 1000000, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.question_text= train_df.question_text.apply(round2)\n",
    "train_df.question_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         what are interesting facts about microsoft his...\n",
       "1         what are those things which are not gonna happ...\n",
       "2         what should i know to avoid being upsold when ...\n",
       "3                   how i add any account with payment bank\n",
       "4         which multi level marketing products are actua...\n",
       "                                ...                        \n",
       "999995                            how is cse at vit chennai\n",
       "999996    how can we prevent a holocaust by robots ai or...\n",
       "999997    how can i help a student remember key steps an...\n",
       "999998    what is the difference between lace closure  l...\n",
       "999999      what happens when you look into a broken mirror\n",
       "Name: question_text, Length: 1000000, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.question_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "Tokenization is the process of segmenting running text into sentences and words. In essence, it’s the task of cutting a text into pieces called tokens. \n",
    "$\\newline$ Here we are going to use word tokenizer i.e. the words are the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/karanjitsaha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "#defining function for tokenization\n",
    "# import re\n",
    "# def tokenization(text):\n",
    "#     tokens = re.split('W+',text)\n",
    "#     return tokens[0].split(\" \")\n",
    "# #applying function to the column\n",
    "# train_df['question_text']= train_df['question_text'].apply(lambda x: tokenization(x))\n",
    "# train_df.iloc[1].question_text\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "def tokenization(text):\n",
    "    return word_tokenize(text)\n",
    "# applying function to the column\n",
    "train_df['question_text']= train_df['question_text'].apply(lambda x: tokenization(x))\n",
    "# train_df.iloc[1].question_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words removal\n",
    "Stop words are commonly occurring words that for some computational processes provide little information or in some cases introduce unnecessary noise and therefore need to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/karanjitsaha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dda0b0efc8ba86e81ec4</td>\n",
       "      <td>[interesting, facts, microsoft, history]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dc708b74a108d0fc0ad9</td>\n",
       "      <td>[things, gon, na, happen, ever]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06a27ec5d82dacd8bfe0</td>\n",
       "      <td>[know, avoid, upsold, getting, car, brakes, ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00cbb6b17e3ceb7c5358</td>\n",
       "      <td>[add, account, payment, bank]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c304888973a701585a0</td>\n",
       "      <td>[multi, level, marketing, products, actually, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>4bd96088d0b5f0f2c4f4</td>\n",
       "      <td>[cse, vit, chennai]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>e80edbfc086f7125940f</td>\n",
       "      <td>[prevent, holocaust, robots, ai, aliens]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>1506dfad6bd340782a1f</td>\n",
       "      <td>[help, student, remember, key, steps, informat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>b56c60fd407f2f85553c</td>\n",
       "      <td>[difference, lace, closure, lace, frontals]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>a1b32d315c2782cdbcc3</td>\n",
       "      <td>[happens, look, broken, mirror]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "0       dda0b0efc8ba86e81ec4   \n",
       "1       dc708b74a108d0fc0ad9   \n",
       "2       06a27ec5d82dacd8bfe0   \n",
       "3       00cbb6b17e3ceb7c5358   \n",
       "4       7c304888973a701585a0   \n",
       "...                      ...   \n",
       "999995  4bd96088d0b5f0f2c4f4   \n",
       "999996  e80edbfc086f7125940f   \n",
       "999997  1506dfad6bd340782a1f   \n",
       "999998  b56c60fd407f2f85553c   \n",
       "999999  a1b32d315c2782cdbcc3   \n",
       "\n",
       "                                            question_text  target  \n",
       "0                [interesting, facts, microsoft, history]       0  \n",
       "1                         [things, gon, na, happen, ever]       0  \n",
       "2       [know, avoid, upsold, getting, car, brakes, ch...       0  \n",
       "3                           [add, account, payment, bank]       0  \n",
       "4       [multi, level, marketing, products, actually, ...       0  \n",
       "...                                                   ...     ...  \n",
       "999995                                [cse, vit, chennai]       0  \n",
       "999996           [prevent, holocaust, robots, ai, aliens]       0  \n",
       "999997  [help, student, remember, key, steps, informat...       0  \n",
       "999998        [difference, lace, closure, lace, frontals]       0  \n",
       "999999                    [happens, look, broken, mirror]       0  \n",
       "\n",
       "[1000000 rows x 3 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "# train_df.question_text = [word for word in train_df.question_text if not word in stopwords.words('english')]\n",
    "# train_df\n",
    "# print(stopwords.words('english'))\n",
    "stopwords=stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    output= [i for i in text if i not in stopwords]\n",
    "    return output\n",
    "#applying the function\n",
    "train_df['question_text']= train_df['question_text'].apply(lambda x:remove_stopwords(x))\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.stem import PorterStemmer\n",
    "# ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['question_text'] = train_df['question_text'].apply(lambda x: [ps.stem(y) for y in x]) # Stem every word.\n",
    "# # train_df = train_df.drop(columns=['question_text']) # Get rid of the unstemmed column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dda0b0efc8ba86e81ec4</td>\n",
       "      <td>[interesting, facts, microsoft, history]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dc708b74a108d0fc0ad9</td>\n",
       "      <td>[things, gon, na, happen, ever]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06a27ec5d82dacd8bfe0</td>\n",
       "      <td>[know, avoid, upsold, getting, car, brakes, ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00cbb6b17e3ceb7c5358</td>\n",
       "      <td>[add, account, payment, bank]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c304888973a701585a0</td>\n",
       "      <td>[multi, level, marketing, products, actually, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>4bd96088d0b5f0f2c4f4</td>\n",
       "      <td>[cse, vit, chennai]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>e80edbfc086f7125940f</td>\n",
       "      <td>[prevent, holocaust, robots, ai, aliens]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>1506dfad6bd340782a1f</td>\n",
       "      <td>[help, student, remember, key, steps, informat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>b56c60fd407f2f85553c</td>\n",
       "      <td>[difference, lace, closure, lace, frontals]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>a1b32d315c2782cdbcc3</td>\n",
       "      <td>[happens, look, broken, mirror]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "0       dda0b0efc8ba86e81ec4   \n",
       "1       dc708b74a108d0fc0ad9   \n",
       "2       06a27ec5d82dacd8bfe0   \n",
       "3       00cbb6b17e3ceb7c5358   \n",
       "4       7c304888973a701585a0   \n",
       "...                      ...   \n",
       "999995  4bd96088d0b5f0f2c4f4   \n",
       "999996  e80edbfc086f7125940f   \n",
       "999997  1506dfad6bd340782a1f   \n",
       "999998  b56c60fd407f2f85553c   \n",
       "999999  a1b32d315c2782cdbcc3   \n",
       "\n",
       "                                            question_text  target  \n",
       "0                [interesting, facts, microsoft, history]       0  \n",
       "1                         [things, gon, na, happen, ever]       0  \n",
       "2       [know, avoid, upsold, getting, car, brakes, ch...       0  \n",
       "3                           [add, account, payment, bank]       0  \n",
       "4       [multi, level, marketing, products, actually, ...       0  \n",
       "...                                                   ...     ...  \n",
       "999995                                [cse, vit, chennai]       0  \n",
       "999996           [prevent, holocaust, robots, ai, aliens]       0  \n",
       "999997  [help, student, remember, key, steps, informat...       0  \n",
       "999998        [difference, lace, closure, lace, frontals]       0  \n",
       "999999                    [happens, look, broken, mirror]       0  \n",
       "\n",
       "[1000000 rows x 3 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "Lemmatization is a tool that performs full morphological analysis to more accurately find the root, or “lemma” for a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/karanjitsaha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "#defining the object for Lemmatization\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "#defining the function for lemmatization\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text\n",
    "train_df['question_text']=train_df['question_text'].apply(lambda x:lemmatizer(x))\n",
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listOfWords = train_df.question_text[:][0]\n",
    "# listOfWords.extend(train_df.question_text[:][1])\n",
    "# listOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# We are going to create a document-term matrix using CountVectorizer, and exclude common English stop words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "words=[]\n",
    "for i in range(train_df.question_text.shape[0]):\n",
    "    words.extend(word for word in train_df.question_text[:][i])\n",
    "# print(words)\n",
    "data_cv = cv.fit_transform(word for word in words)\n",
    "# data_cv = train_df.question_text \n",
    "data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names_out())\n",
    "# data_dtm.index = train_df.index\n",
    "data_dtm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
