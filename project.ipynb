{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing important libraries and reading the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt \n",
    "train_df = pd.read_csv(\"train_df.csv\")\n",
    "test_df = pd.read_csv(\"test_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for null values, invalid target values and duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df.head(9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.061870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.240919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               target\n",
       "count  1000000.000000\n",
       "mean         0.061870\n",
       "std          0.240919\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          1.000000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid              0\n",
       "question_text    0\n",
       "target           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"target\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.index[train_df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for null values and duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a4f3da3a3df9dd881edd</td>\n",
       "      <td>My period is due on my wedding day. How can I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9914c62ed3f69684d549</td>\n",
       "      <td>How many numbers higher than a million can be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8138ae48649e37091a91</td>\n",
       "      <td>How come I feel nothing for my family, but sti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>981b4753d17ef14d09f7</td>\n",
       "      <td>In case of collapse of the Democratic party, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>452e2c705276ba16b7b7</td>\n",
       "      <td>Who is Émile Naoumoff?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306117</th>\n",
       "      <td>a352dff4fcc2571815ce</td>\n",
       "      <td>Did anyone get an update on Maruti Suzuki All ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306118</th>\n",
       "      <td>ad4a8498d97c536c67b9</td>\n",
       "      <td>What 5 people in history do you find the most ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306119</th>\n",
       "      <td>19784a27b55d4b453fda</td>\n",
       "      <td>How can I remove the tan on my forehead?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306120</th>\n",
       "      <td>370191dba26465997879</td>\n",
       "      <td>If you are a well known hacker, will you be mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306121</th>\n",
       "      <td>8077b4a45cea867d4ff2</td>\n",
       "      <td>If your new enemies be bigger and more dangero...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306122 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "0       a4f3da3a3df9dd881edd   \n",
       "1       9914c62ed3f69684d549   \n",
       "2       8138ae48649e37091a91   \n",
       "3       981b4753d17ef14d09f7   \n",
       "4       452e2c705276ba16b7b7   \n",
       "...                      ...   \n",
       "306117  a352dff4fcc2571815ce   \n",
       "306118  ad4a8498d97c536c67b9   \n",
       "306119  19784a27b55d4b453fda   \n",
       "306120  370191dba26465997879   \n",
       "306121  8077b4a45cea867d4ff2   \n",
       "\n",
       "                                            question_text  \n",
       "0       My period is due on my wedding day. How can I ...  \n",
       "1       How many numbers higher than a million can be ...  \n",
       "2       How come I feel nothing for my family, but sti...  \n",
       "3       In case of collapse of the Democratic party, w...  \n",
       "4                                  Who is Émile Naoumoff?  \n",
       "...                                                   ...  \n",
       "306117  Did anyone get an update on Maruti Suzuki All ...  \n",
       "306118  What 5 people in history do you find the most ...  \n",
       "306119           How can I remove the tan on my forehead?  \n",
       "306120  If you are a well known hacker, will you be mo...  \n",
       "306121  If your new enemies be bigger and more dangero...  \n",
       "\n",
       "[306122 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid              0\n",
       "question_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.index[test_df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the text\n",
    "Common data cleaning steps on all text:\n",
    "\n",
    "1.Make text all lower case\n",
    "\n",
    "2.Remove punctuation\n",
    "\n",
    "3.Remove numerical values\n",
    "\n",
    "4.Remove common non-sensical text (/n)\n",
    "\n",
    "5.Tokenize text\n",
    "\n",
    "6.Remove stop words\n",
    "\n",
    "7.Stemming / lemmatization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here (in round 1) we are doing the following things:-\n",
    "1. Making the text lower case.\n",
    "2. Removing text in square brackets\n",
    "3. Removing punctuation marks from the text\n",
    "4. Removing words containing numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text_round1(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "round1 = lambda x: clean_text_round1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.question_text= train_df.question_text.apply(round1)\n",
    "# train_df.question_text\n",
    "test_df.question_text= test_df.question_text.apply(round1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here (in round2) we are doing:-\n",
    "1. Getting rid of additional punctuation\n",
    "2. Removing some non-sensical text\n",
    "3. Removing urls\n",
    "4. Removing HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a second round of cleaning\n",
    "def clean_text_round2(text):\n",
    "    '''Get rid of some additional punctuation and non-sensical text that was missed the first time around.'''\n",
    "    text = re.sub('[‘’“”…]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub(r\"http\\S+\", '', text)\n",
    "    text = re.sub(re.compile('<.*?>') , '', text)\n",
    "\n",
    "    return text\n",
    "round2 = lambda x: clean_text_round2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         my period is due on my wedding day how can i s...\n",
       "1         how many numbers higher than a million can be ...\n",
       "2         how come i feel nothing for my family but stil...\n",
       "3         in case of collapse of the democratic party wi...\n",
       "4                                     who is émile naoumoff\n",
       "                                ...                        \n",
       "306117    did anyone get an update on maruti suzuki all ...\n",
       "306118    what  people in history do you find the most i...\n",
       "306119              how can i remove the tan on my forehead\n",
       "306120    if you are a well known hacker will you be mor...\n",
       "306121    if your new enemies be bigger and more dangero...\n",
       "Name: question_text, Length: 306122, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.question_text= train_df.question_text.apply(round2)\n",
    "test_df.question_text= test_df.question_text.apply(round2)\n",
    "test_df.question_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.question_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "Tokenization is the process of segmenting running text into sentences and words. In essence, it’s the task of cutting a text into pieces called tokens. \n",
    "$\\newline$ Here we are going to use word tokenizer i.e. the words are the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/karanjitsaha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "def tokenization(text):\n",
    "    return word_tokenize(text)\n",
    "# applying function to the column\n",
    "train_df['question_text']= train_df['question_text'].apply(lambda x: tokenization(x))\n",
    "test_df['question_text']= test_df['question_text'].apply(lambda x: tokenization(x))\n",
    "\n",
    "# train_df.iloc[1].question_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [what, are, interesting, facts, about, microso...\n",
       "1         [what, are, those, things, which, are, not, go...\n",
       "2         [what, should, i, know, to, avoid, being, upso...\n",
       "3          [how, i, add, any, account, with, payment, bank]\n",
       "4         [which, multi, level, marketing, products, are...\n",
       "                                ...                        \n",
       "999995                     [how, is, cse, at, vit, chennai]\n",
       "999996    [how, can, we, prevent, a, holocaust, by, robo...\n",
       "999997    [how, can, i, help, a, student, remember, key,...\n",
       "999998    [what, is, the, difference, between, lace, clo...\n",
       "999999    [what, happens, when, you, look, into, a, brok...\n",
       "Name: question_text, Length: 1000000, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.question_text\n",
    "# import nltk\n",
    "# from nltk.stem import PorterStemmer\n",
    "# ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['question_text'] = train_df['question_text'].apply(lambda x: [ps.stem(y) for y in x]) # Stem every word.\n",
    "# # train_df = train_df.drop(columns=['question_text']) # Get rid of the unstemmed column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a4f3da3a3df9dd881edd</td>\n",
       "      <td>[my, period, is, due, on, my, wedding, day, ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9914c62ed3f69684d549</td>\n",
       "      <td>[how, many, numbers, higher, than, a, million,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8138ae48649e37091a91</td>\n",
       "      <td>[how, come, i, feel, nothing, for, my, family,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>981b4753d17ef14d09f7</td>\n",
       "      <td>[in, case, of, collapse, of, the, democratic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>452e2c705276ba16b7b7</td>\n",
       "      <td>[who, is, émile, naoumoff]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306117</th>\n",
       "      <td>a352dff4fcc2571815ce</td>\n",
       "      <td>[did, anyone, get, an, update, on, maruti, suz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306118</th>\n",
       "      <td>ad4a8498d97c536c67b9</td>\n",
       "      <td>[what, people, in, history, do, you, find, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306119</th>\n",
       "      <td>19784a27b55d4b453fda</td>\n",
       "      <td>[how, can, i, remove, the, tan, on, my, forehead]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306120</th>\n",
       "      <td>370191dba26465997879</td>\n",
       "      <td>[if, you, are, a, well, known, hacker, will, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306121</th>\n",
       "      <td>8077b4a45cea867d4ff2</td>\n",
       "      <td>[if, your, new, enemies, be, bigger, and, more...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306122 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "0       a4f3da3a3df9dd881edd   \n",
       "1       9914c62ed3f69684d549   \n",
       "2       8138ae48649e37091a91   \n",
       "3       981b4753d17ef14d09f7   \n",
       "4       452e2c705276ba16b7b7   \n",
       "...                      ...   \n",
       "306117  a352dff4fcc2571815ce   \n",
       "306118  ad4a8498d97c536c67b9   \n",
       "306119  19784a27b55d4b453fda   \n",
       "306120  370191dba26465997879   \n",
       "306121  8077b4a45cea867d4ff2   \n",
       "\n",
       "                                            question_text  \n",
       "0       [my, period, is, due, on, my, wedding, day, ho...  \n",
       "1       [how, many, numbers, higher, than, a, million,...  \n",
       "2       [how, come, i, feel, nothing, for, my, family,...  \n",
       "3       [in, case, of, collapse, of, the, democratic, ...  \n",
       "4                              [who, is, émile, naoumoff]  \n",
       "...                                                   ...  \n",
       "306117  [did, anyone, get, an, update, on, maruti, suz...  \n",
       "306118  [what, people, in, history, do, you, find, the...  \n",
       "306119  [how, can, i, remove, the, tan, on, my, forehead]  \n",
       "306120  [if, you, are, a, well, known, hacker, will, y...  \n",
       "306121  [if, your, new, enemies, be, bigger, and, more...  \n",
       "\n",
       "[306122 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "Lemmatization is a tool that performs full morphological analysis to more accurately find the root, or “lemma” for a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/karanjitsaha/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/karanjitsaha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dda0b0efc8ba86e81ec4</td>\n",
       "      <td>[what, are, interesting, fact, about, microsof...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dc708b74a108d0fc0ad9</td>\n",
       "      <td>[what, are, those, thing, which, are, not, gon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06a27ec5d82dacd8bfe0</td>\n",
       "      <td>[what, should, i, know, to, avoid, being, upso...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00cbb6b17e3ceb7c5358</td>\n",
       "      <td>[how, i, add, any, account, with, payment, bank]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c304888973a701585a0</td>\n",
       "      <td>[which, multi, level, marketing, product, are,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>4bd96088d0b5f0f2c4f4</td>\n",
       "      <td>[how, is, cse, at, vit, chennai]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>e80edbfc086f7125940f</td>\n",
       "      <td>[how, can, we, prevent, a, holocaust, by, robo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>1506dfad6bd340782a1f</td>\n",
       "      <td>[how, can, i, help, a, student, remember, key,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>b56c60fd407f2f85553c</td>\n",
       "      <td>[what, is, the, difference, between, lace, clo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>a1b32d315c2782cdbcc3</td>\n",
       "      <td>[what, happens, when, you, look, into, a, brok...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "0       dda0b0efc8ba86e81ec4   \n",
       "1       dc708b74a108d0fc0ad9   \n",
       "2       06a27ec5d82dacd8bfe0   \n",
       "3       00cbb6b17e3ceb7c5358   \n",
       "4       7c304888973a701585a0   \n",
       "...                      ...   \n",
       "999995  4bd96088d0b5f0f2c4f4   \n",
       "999996  e80edbfc086f7125940f   \n",
       "999997  1506dfad6bd340782a1f   \n",
       "999998  b56c60fd407f2f85553c   \n",
       "999999  a1b32d315c2782cdbcc3   \n",
       "\n",
       "                                            question_text  target  \n",
       "0       [what, are, interesting, fact, about, microsof...       0  \n",
       "1       [what, are, those, thing, which, are, not, gon...       0  \n",
       "2       [what, should, i, know, to, avoid, being, upso...       0  \n",
       "3        [how, i, add, any, account, with, payment, bank]       0  \n",
       "4       [which, multi, level, marketing, product, are,...       0  \n",
       "...                                                   ...     ...  \n",
       "999995                   [how, is, cse, at, vit, chennai]       0  \n",
       "999996  [how, can, we, prevent, a, holocaust, by, robo...       0  \n",
       "999997  [how, can, i, help, a, student, remember, key,...       0  \n",
       "999998  [what, is, the, difference, between, lace, clo...       0  \n",
       "999999  [what, happens, when, you, look, into, a, brok...       0  \n",
       "\n",
       "[1000000 rows x 3 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "# Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "#defining the object for Lemmatization\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "#defining the function for lemmatization\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text\n",
    "train_df['question_text']=train_df['question_text'].apply(lambda x:lemmatizer(x))\n",
    "test_df['question_text']=test_df['question_text'].apply(lambda x:lemmatizer(x))\n",
    "# train_df.shape\n",
    "train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what',\n",
       " 'are',\n",
       " 'those',\n",
       " 'thing',\n",
       " 'which',\n",
       " 'are',\n",
       " 'not',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'happen',\n",
       " 'ever']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"question_text\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words removal\n",
    "Stop words are commonly occurring words that for some computational processes provide little information or in some cases introduce unnecessary noise and therefore need to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "# # train_df.question_text = [word for word in train_df.question_text if not word in stopwords.words('english')]\n",
    "# # train_df\n",
    "# # print(stopwords.words('english'))\n",
    "# stopwords=stopwords.words('english')\n",
    "# def remove_stopwords(text):\n",
    "#     output= [i for i in text if i not in stopwords]\n",
    "#     return output\n",
    "# #applying the function\n",
    "# train_df['question_text']= train_df['question_text'].apply(lambda x:remove_stopwords(x))\n",
    "# test_df['question_text']= test_df['question_text'].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_stopwords(lemmatizer([\"thing\",\"gonna\",\"happen\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dda0b0efc8ba86e81ec4</td>\n",
       "      <td>[what, are, interesting, fact, about, microsof...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dc708b74a108d0fc0ad9</td>\n",
       "      <td>[what, are, those, thing, which, are, not, gon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06a27ec5d82dacd8bfe0</td>\n",
       "      <td>[what, should, i, know, to, avoid, being, upso...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00cbb6b17e3ceb7c5358</td>\n",
       "      <td>[how, i, add, any, account, with, payment, bank]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c304888973a701585a0</td>\n",
       "      <td>[which, multi, level, marketing, product, are,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>4bd96088d0b5f0f2c4f4</td>\n",
       "      <td>[how, is, cse, at, vit, chennai]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>e80edbfc086f7125940f</td>\n",
       "      <td>[how, can, we, prevent, a, holocaust, by, robo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>1506dfad6bd340782a1f</td>\n",
       "      <td>[how, can, i, help, a, student, remember, key,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>b56c60fd407f2f85553c</td>\n",
       "      <td>[what, is, the, difference, between, lace, clo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>a1b32d315c2782cdbcc3</td>\n",
       "      <td>[what, happens, when, you, look, into, a, brok...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "0       dda0b0efc8ba86e81ec4   \n",
       "1       dc708b74a108d0fc0ad9   \n",
       "2       06a27ec5d82dacd8bfe0   \n",
       "3       00cbb6b17e3ceb7c5358   \n",
       "4       7c304888973a701585a0   \n",
       "...                      ...   \n",
       "999995  4bd96088d0b5f0f2c4f4   \n",
       "999996  e80edbfc086f7125940f   \n",
       "999997  1506dfad6bd340782a1f   \n",
       "999998  b56c60fd407f2f85553c   \n",
       "999999  a1b32d315c2782cdbcc3   \n",
       "\n",
       "                                            question_text  target  \n",
       "0       [what, are, interesting, fact, about, microsof...       0  \n",
       "1       [what, are, those, thing, which, are, not, gon...       0  \n",
       "2       [what, should, i, know, to, avoid, being, upso...       0  \n",
       "3        [how, i, add, any, account, with, payment, bank]       0  \n",
       "4       [which, multi, level, marketing, product, are,...       0  \n",
       "...                                                   ...     ...  \n",
       "999995                   [how, is, cse, at, vit, chennai]       0  \n",
       "999996  [how, can, we, prevent, a, holocaust, by, robo...       0  \n",
       "999997  [how, can, i, help, a, student, remember, key,...       0  \n",
       "999998  [what, is, the, difference, between, lace, clo...       0  \n",
       "999999  [what, happens, when, you, look, into, a, brok...       0  \n",
       "\n",
       "[1000000 rows x 3 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         what are interesting fact about microsoft history\n",
      "1         what are those thing which are not gon na happ...\n",
      "2         what should i know to avoid being upsold when ...\n",
      "3                   how i add any account with payment bank\n",
      "4         which multi level marketing product are actual...\n",
      "                                ...                        \n",
      "999995                            how is cse at vit chennai\n",
      "999996    how can we prevent a holocaust by robot ai or ...\n",
      "999997    how can i help a student remember key step and...\n",
      "999998    what is the difference between lace closure la...\n",
      "999999      what happens when you look into a broken mirror\n",
      "Name: question_text, Length: 1000000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def makeSentence(text):\n",
    "    return ' '.join(list(text))\n",
    "\n",
    "train_df.question_text = train_df['question_text'].apply(lambda x: makeSentence(x))\n",
    "test_df.question_text = test_df['question_text'].apply(lambda x: makeSentence(x))\n",
    "\n",
    "print(train_df.question_text)\n",
    "# print(makeSentence(train_df.question_text[0]))\n",
    "# ' '.join(list(train_df.question_text)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing train test split of the train_df.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df.question_text, train_df.target.values , test_size=0.15, random_state=0)\n",
    "X_train.shape\n",
    "\n",
    "test_x = test_df.question_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Import modules for evaluation purposes\n",
    "# Import libraries for predcton\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,roc_auc_score,roc_curve,auc,f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "tfidf = CountVectorizer()\n",
    "# Numericalize the train dataset\n",
    "train = tfidf.fit_transform(X_train.values.astype('U'))\n",
    "# Numericalize the test dataset\n",
    "test = tfidf.transform(X_test.values.astype('U'))\n",
    "\n",
    "# for test_df\n",
    "test_df_matrix = tfidf.transform(test_x.values.astype('U'))\n",
    "print(test_df_matrix.shape)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'can': 8630,\n",
       " 'you': 65741,\n",
       " 'show': 53526,\n",
       " 'that': 58833,\n",
       " 'the': 58847,\n",
       " 'curve': 13703,\n",
       " 'ha': 24765,\n",
       " 'three': 59114,\n",
       " 'inflection': 28633,\n",
       " 'point': 45078,\n",
       " 'on': 41602,\n",
       " 'they': 58982,\n",
       " 'all': 1656,\n",
       " 'lie': 33447,\n",
       " 'one': 41623,\n",
       " 'straight': 56381,\n",
       " 'line': 33615,\n",
       " 'how': 26808,\n",
       " 'do': 16611,\n",
       " 'have': 25452,\n",
       " 'sex': 52883,\n",
       " 'orally': 41905,\n",
       " 'what': 64364,\n",
       " 'is': 29744,\n",
       " 'life': 33458,\n",
       " 'and': 2268,\n",
       " 'death': 14353,\n",
       " 'cause': 9253,\n",
       " 'toilet': 59568,\n",
       " 'to': 59503,\n",
       " 'keep': 31392,\n",
       " 'running': 50879,\n",
       " 'continuously': 12311,\n",
       " 'best': 5884,\n",
       " 'way': 63996,\n",
       " 'start': 55951,\n",
       " 'out': 42214,\n",
       " 'blogging': 6742,\n",
       " 'make': 34937,\n",
       " 'money': 37848,\n",
       " 'why': 64602,\n",
       " 'so': 54685,\n",
       " 'many': 35331,\n",
       " 'people': 43774,\n",
       " 'ignore': 27658,\n",
       " 'fact': 20216,\n",
       " 'think': 59020,\n",
       " 'men': 36427,\n",
       " 'woman': 64968,\n",
       " 'could': 12793,\n",
       " 'use': 62297,\n",
       " 'technology': 58367,\n",
       " 'change': 9727,\n",
       " 'dating': 14191,\n",
       " 'for': 21682,\n",
       " 'better': 5940,\n",
       " 'should': 53502,\n",
       " 'younger': 65750,\n",
       " 'person': 43990,\n",
       " 'always': 1905,\n",
       " 'greet': 24260,\n",
       " 'older': 41496,\n",
       " 'first': 21162,\n",
       " 'it': 29915,\n",
       " 'important': 28050,\n",
       " 'respect': 49637,\n",
       " 'others': 42174,\n",
       " 'doe': 16663,\n",
       " 'job': 30568,\n",
       " 'mean': 36119,\n",
       " 'who': 64559,\n",
       " 'are': 3271,\n",
       " 'your': 65757,\n",
       " 'greatest': 24222,\n",
       " 'basketball': 5239,\n",
       " 'player': 44859,\n",
       " 'of': 41349,\n",
       " 'alltime': 1756,\n",
       " 'wa': 63611,\n",
       " 'alcatraz': 1512,\n",
       " 'island': 29828,\n",
       " 'prison': 46285,\n",
       " 'closed': 10875,\n",
       " 'reasonable': 48401,\n",
       " 'stating': 56008,\n",
       " 'nonbinary': 40323,\n",
       " 'dont': 16793,\n",
       " 'exist': 19833,\n",
       " 'count': 12818,\n",
       " 'bnbr': 6885,\n",
       " 'violation': 63204,\n",
       " 'function': 22407,\n",
       " 'torpedo': 59762,\n",
       " 'plan': 44773,\n",
       " 'studying': 56616,\n",
       " 'computer': 11747,\n",
       " 'science': 51905,\n",
       " 'once': 41613,\n",
       " 'enter': 18841,\n",
       " 'college': 11271,\n",
       " 'expect': 19896,\n",
       " 'my': 38844,\n",
       " 'future': 22496,\n",
       " 'typically': 60898,\n",
       " 'look': 34081,\n",
       " 'like': 33536,\n",
       " 'if': 27594,\n",
       " 'want': 63783,\n",
       " 'end': 18605,\n",
       " 'up': 62064,\n",
       " 'wall': 63727,\n",
       " 'street': 56464,\n",
       " 'smarter': 54443,\n",
       " 'take': 57932,\n",
       " 'texas': 58746,\n",
       " 'am': 1912,\n",
       " 'university': 61720,\n",
       " 'or': 41900,\n",
       " 'attend': 4056,\n",
       " 'dartmouth': 14135,\n",
       " 'at': 3919,\n",
       " 'full': 22369,\n",
       " 'price': 46195,\n",
       " 'uk': 61073,\n",
       " 'didnt': 15703,\n",
       " 'vote': 63516,\n",
       " 'fudge': 22330,\n",
       " 'membership': 36396,\n",
       " 'eu': 19427,\n",
       " 'custom': 13727,\n",
       " 'union': 61677,\n",
       " 'andor': 2293,\n",
       " 'single': 53954,\n",
       " 'market': 35471,\n",
       " 'still': 56223,\n",
       " 'mooted': 38022,\n",
       " 'after': 1052,\n",
       " 'leave': 33009,\n",
       " 'which': 64461,\n",
       " 'institute': 29019,\n",
       " 'in': 28142,\n",
       " 'india': 28378,\n",
       " 'vlsi': 63390,\n",
       " 'backend': 4634,\n",
       " 'coaching': 10986,\n",
       " 'along': 1791,\n",
       " 'with': 64874,\n",
       " 'training': 59971,\n",
       " 'fee': 20683,\n",
       " 'nursing': 40980,\n",
       " 'intervention': 29332,\n",
       " 'woody': 65027,\n",
       " 'edema': 17835,\n",
       " 'foot': 21659,\n",
       " 'candice': 8668,\n",
       " 'major': 34920,\n",
       " 'accomplishment': 345,\n",
       " 'an': 2173,\n",
       " 'actress': 571,\n",
       " 'despite': 15290,\n",
       " 'lalu': 32536,\n",
       " 'yadav': 65480,\n",
       " 'decimating': 14459,\n",
       " 'land': 32588,\n",
       " 'bihar': 6225,\n",
       " 'bringing': 7681,\n",
       " 'did': 15694,\n",
       " 'rjd': 50296,\n",
       " 'get': 23240,\n",
       " 'majority': 34926,\n",
       " 'election': 18122,\n",
       " 'some': 54940,\n",
       " 'process': 46373,\n",
       " 'data': 14161,\n",
       " 'collection': 11261,\n",
       " 'pulsar': 47089,\n",
       " 'supernova': 57227,\n",
       " 'remnant': 49238,\n",
       " 'surrounding': 57394,\n",
       " 'them': 58873,\n",
       " 'natural': 39286,\n",
       " 'frequency': 22127,\n",
       " 'steel': 56068,\n",
       " 'beam': 5438,\n",
       " 'difference': 15754,\n",
       " 'between': 5953,\n",
       " 'material': 35744,\n",
       " 'set': 52823,\n",
       " 'theory': 58917,\n",
       " 'structural': 56561,\n",
       " 'lack': 32436,\n",
       " 'any': 2866,\n",
       " 'motivation': 38197,\n",
       " 'anything': 2878,\n",
       " 'fix': 21226,\n",
       " 'indian': 28389,\n",
       " 'done': 16778,\n",
       " 'master': 35679,\n",
       " 'offer': 41375,\n",
       " 'europe': 19472,\n",
       " 'bet': 5909,\n",
       " 'sure': 57344,\n",
       " 'ico': 27475,\n",
       " 'token': 59574,\n",
       " 'not': 40724,\n",
       " 'security': 52286,\n",
       " 'under': 61363,\n",
       " 'law': 32849,\n",
       " 'then': 58888,\n",
       " 'where': 64437,\n",
       " 'legal': 33077,\n",
       " 'opinion': 41803,\n",
       " 'we': 64029,\n",
       " 'see': 52314,\n",
       " 'were': 64290,\n",
       " 'going': 23780,\n",
       " 'buy': 8308,\n",
       " 'commercial': 11481,\n",
       " 'property': 46655,\n",
       " 'big': 6198,\n",
       " 'investment': 29516,\n",
       " 'would': 65162,\n",
       " 'structure': 56564,\n",
       " 'financing': 21069,\n",
       " 'there': 58927,\n",
       " 'particular': 43190,\n",
       " 'hour': 26767,\n",
       " 'before': 5566,\n",
       " 'dawn': 14228,\n",
       " 'nicherin': 39937,\n",
       " 'buddhist': 7987,\n",
       " 'monk': 37878,\n",
       " 'pray': 45781,\n",
       " 'called': 8520,\n",
       " 'biggest': 6210,\n",
       " 'flaw': 21340,\n",
       " 'newer': 39827,\n",
       " 'generation': 23044,\n",
       " 'say': 51667,\n",
       " 'girl': 23447,\n",
       " 'ask': 3678,\n",
       " 'whats': 64388,\n",
       " 'idea': 27503,\n",
       " 'world': 65098,\n",
       " 'exam': 19644,\n",
       " 'date': 14183,\n",
       " 'nainital': 39001,\n",
       " 'bank': 4995,\n",
       " 'clerk': 10770,\n",
       " 'recruitment': 48622,\n",
       " 'exercise': 19779,\n",
       " 'quentin': 47532,\n",
       " 'express': 20007,\n",
       " 'character': 9773,\n",
       " 'his': 26290,\n",
       " 'painting': 42736,\n",
       " 'true': 60480,\n",
       " 'original': 42007,\n",
       " 'jew': 30425,\n",
       " 'exiled': 19829,\n",
       " 'from': 22230,\n",
       " 'israel': 29882,\n",
       " 'by': 8344,\n",
       " 'roman': 50507,\n",
       " 'thought': 59090,\n",
       " 'about': 168,\n",
       " 'this': 59054,\n",
       " 'our': 42203,\n",
       " 'eye': 20125,\n",
       " 'restrict': 49702,\n",
       " 'thing': 59016,\n",
       " 'only': 41685,\n",
       " 'upto': 62172,\n",
       " 'dimension': 15891,\n",
       " 'filter': 21034,\n",
       " 'regard': 48917,\n",
       " 'also': 1836,\n",
       " 'fundamentally': 22423,\n",
       " 'differentiates': 15763,\n",
       " 'real': 48341,\n",
       " 'american': 2019,\n",
       " 'those': 59083,\n",
       " 'try': 60539,\n",
       " 'fake': 20290,\n",
       " 'henry': 25858,\n",
       " 'clifford': 10800,\n",
       " 'kinley': 31793,\n",
       " 'found': 21883,\n",
       " 'divine': 16520,\n",
       " 'metaphysical': 36676,\n",
       " 'research': 49535,\n",
       " 'alternate': 1853,\n",
       " 'traditional': 59944,\n",
       " 'personality': 43997,\n",
       " 'type': 60878,\n",
       " 'someone': 54949,\n",
       " 'help': 25786,\n",
       " 'me': 36105,\n",
       " 'speech': 55323,\n",
       " 'iq': 29634,\n",
       " 'test': 58692,\n",
       " 'valid': 62541,\n",
       " 'measurement': 36146,\n",
       " 'human': 26963,\n",
       " 'intelligence': 29099,\n",
       " 'working': 65080,\n",
       " 'convenience': 12386,\n",
       " 'store': 56341,\n",
       " 'be': 5420,\n",
       " 'counted': 12821,\n",
       " 'work': 65058,\n",
       " 'experience': 19927,\n",
       " 'cat': 9141,\n",
       " 'perspective': 44012,\n",
       " 'anyone': 2874,\n",
       " 'watch': 63903,\n",
       " 'yuri': 65835,\n",
       " 'ice': 27437,\n",
       " 'ukraine': 61081,\n",
       " 'might': 37024,\n",
       " 'attacked': 4038,\n",
       " 'behave': 5604,\n",
       " 'classmate': 10692,\n",
       " 'tease': 58330,\n",
       " 'class': 10673,\n",
       " 'doubt': 16902,\n",
       " 'instead': 29001,\n",
       " 'question': 47541,\n",
       " 'department': 15060,\n",
       " 'will': 64721,\n",
       " 'able': 135,\n",
       " 'practice': 45710,\n",
       " 'passing': 43250,\n",
       " 'usmle': 62341,\n",
       " 'company': 11573,\n",
       " 'hire': 26272,\n",
       " 'semi': 52570,\n",
       " 'qualified': 47446,\n",
       " 'ca': 8375,\n",
       " 'remainder': 49180,\n",
       " 'spam': 55192,\n",
       " 'yoi': 65698,\n",
       " 'inclusion': 28250,\n",
       " 'common': 11515,\n",
       " 'example': 19652,\n",
       " 'homonym': 26548,\n",
       " 'word': 65042,\n",
       " 'placed': 44741,\n",
       " 'colder': 11206,\n",
       " 'london': 34025,\n",
       " 'toronto': 59761,\n",
       " 'year': 65579,\n",
       " 'round': 50678,\n",
       " 'prerequisite': 46051,\n",
       " 'fluid': 21497,\n",
       " 'mechanic': 36163,\n",
       " 'mahatma': 34834,\n",
       " 'gandhi': 22711,\n",
       " 'fight': 20972,\n",
       " 'against': 1082,\n",
       " 'discrimination': 16154,\n",
       " 'both': 7232,\n",
       " 'african': 1027,\n",
       " 'south': 55117,\n",
       " 'africa': 1026,\n",
       " 'tool': 59669,\n",
       " 'good': 23857,\n",
       " 'making': 34952,\n",
       " 'final': 21047,\n",
       " 'semester': 52569,\n",
       " 'schedule': 51807,\n",
       " 'star': 55911,\n",
       " 'universe': 61712,\n",
       " 'opportunity': 41826,\n",
       " 'md': 36089,\n",
       " 'doing': 16701,\n",
       " 'without': 64893,\n",
       " 'ore': 41948,\n",
       " 'filed': 21001,\n",
       " 'restraining': 49698,\n",
       " 'order': 41935,\n",
       " 'received': 48479,\n",
       " 'subpoena': 56788,\n",
       " 'deposition': 15113,\n",
       " 'prepared': 46013,\n",
       " 'proof': 46616,\n",
       " 'equation': 19057,\n",
       " 'interview': 29337,\n",
       " 'day': 14234,\n",
       " 'table': 57831,\n",
       " 'need': 39493,\n",
       " 'negotiated': 39549,\n",
       " 'everyone': 19573,\n",
       " 'speak': 55257,\n",
       " 'hindi': 26216,\n",
       " 'plugin': 44959,\n",
       " 'add': 633,\n",
       " 'search': 52183,\n",
       " 'functionality': 22411,\n",
       " 'dashboard': 14152,\n",
       " 'wp': 65177,\n",
       " 'site': 54057,\n",
       " 'itself': 29966,\n",
       " 'elon': 18296,\n",
       " 'musk': 38754,\n",
       " 'catholic': 9217,\n",
       " 'worth': 65145,\n",
       " 'immigrate': 27928,\n",
       " 'china': 10128,\n",
       " 'nit': 40119,\n",
       " 'into': 29375,\n",
       " 'another': 2533,\n",
       " 'giving': 23492,\n",
       " 'jee': 30327,\n",
       " 'main': 34879,\n",
       " 'again': 1081,\n",
       " 'maid': 34865,\n",
       " 'honor': 26586,\n",
       " 'bridesmaid': 7635,\n",
       " 'hindu': 26225,\n",
       " 'ignorant': 27655,\n",
       " 'intolerant': 29378,\n",
       " 'hospital': 26711,\n",
       " 'gap': 22751,\n",
       " 'almost': 1778,\n",
       " 'currency': 13680,\n",
       " 'hardest': 25223,\n",
       " 'video': 63061,\n",
       " 'game': 22671,\n",
       " 'youve': 65776,\n",
       " 'ever': 19549,\n",
       " 'played': 44858,\n",
       " 'fairly': 20270,\n",
       " 'tall': 57986,\n",
       " 'wrong': 65235,\n",
       " 'prefer': 45908,\n",
       " 'taller': 57989,\n",
       " 'than': 58810,\n",
       " 'must': 38771,\n",
       " 'studied': 56610,\n",
       " 'baymax': 5354,\n",
       " 'avoid': 4400,\n",
       " 'family': 20349,\n",
       " 'member': 36393,\n",
       " 'doesnt': 16673,\n",
       " 'fulfill': 22362,\n",
       " 'promise': 46577,\n",
       " 'ignores': 27660,\n",
       " 'mother': 38172,\n",
       " 'request': 49492,\n",
       " 'improve': 28112,\n",
       " 'behavior': 5608,\n",
       " 'even': 19538,\n",
       " 'though': 59088,\n",
       " 'she': 53170,\n",
       " 'him': 26185,\n",
       " 'accommodation': 332,\n",
       " 'minimum': 37232,\n",
       " 'trade': 59930,\n",
       " 'option': 41884,\n",
       " 'cash': 9066,\n",
       " 'account': 354,\n",
       " 'status': 56028,\n",
       " 'standard': 55876,\n",
       " 'development': 15433,\n",
       " 'technical': 58353,\n",
       " 'support': 57295,\n",
       " 'deployment': 15093,\n",
       " 'lte': 34312,\n",
       " 'bitcoin': 6490,\n",
       " 'android': 2310,\n",
       " 'possible': 45481,\n",
       " 'integrate': 29079,\n",
       " 'education': 17889,\n",
       " 'lm': 33847,\n",
       " 'other': 42170,\n",
       " 'application': 3039,\n",
       " 'when': 64428,\n",
       " 'donald': 16766,\n",
       " 'trump': 60495,\n",
       " 'stop': 56326,\n",
       " 'holding': 26435,\n",
       " 'rally': 47955,\n",
       " 'himself': 26201,\n",
       " 'reference': 48811,\n",
       " 'book': 7074,\n",
       " 'vise': 63261,\n",
       " 'board': 6896,\n",
       " 'examination': 19646,\n",
       " 'writer': 65224,\n",
       " 'poet': 45062,\n",
       " 'giant': 23339,\n",
       " 'cigarette': 10447,\n",
       " 'jeanpaul': 30318,\n",
       " 'smoked': 54504,\n",
       " 'breathless': 7558,\n",
       " 'creative': 13101,\n",
       " 'weird': 64203,\n",
       " 'answer': 2549,\n",
       " 'asked': 3681,\n",
       " 'silent': 53809,\n",
       " 'disco': 16099,\n",
       " 'delhi': 14796,\n",
       " 'importance': 28049,\n",
       " 'biochemistry': 6323,\n",
       " 'medical': 36212,\n",
       " 'field': 20946,\n",
       " 'ricky': 50100,\n",
       " 'gervais': 23231,\n",
       " 'karl': 31192,\n",
       " 'new': 39816,\n",
       " 'podcast': 45048,\n",
       " 'together': 59557,\n",
       " 'army': 3394,\n",
       " 'restroom': 49710,\n",
       " 'light': 33498,\n",
       " 'software': 54814,\n",
       " 'testing': 58709,\n",
       " 'different': 15757,\n",
       " 'most': 38156,\n",
       " 'popular': 45352,\n",
       " 'groped': 24378,\n",
       " 'today': 59530,\n",
       " 'describes': 15210,\n",
       " 'no': 40209,\n",
       " 'rebirth': 48428,\n",
       " 'cornell': 12603,\n",
       " 'suny': 57151,\n",
       " 'affiliated': 976,\n",
       " 'campus': 8624,\n",
       " 'covered': 12924,\n",
       " 'scholarship': 51847,\n",
       " 'jennifer': 30375,\n",
       " 'lawrence': 32864,\n",
       " 'follow': 21607,\n",
       " 'aditya': 711,\n",
       " 'seal': 52165,\n",
       " 'kayastha': 31326,\n",
       " 'choose': 10261,\n",
       " 'power': 45638,\n",
       " 'automation': 4289,\n",
       " 'iit': 27733,\n",
       " 'compare': 11585,\n",
       " 'basis': 5237,\n",
       " 'course': 12879,\n",
       " 'load': 33870,\n",
       " 'placement': 44743,\n",
       " 'allow': 1736,\n",
       " 'study': 56615,\n",
       " 'gmat': 23660,\n",
       " 'back': 4622,\n",
       " 'backwards': 4685,\n",
       " 'primitive': 46232,\n",
       " 'guy': 24701,\n",
       " 'jealous': 30303,\n",
       " 'their': 58865,\n",
       " 'close': 10873,\n",
       " 'friend': 22166,\n",
       " 'getting': 23253,\n",
       " 'hit': 26321,\n",
       " 'couple': 12867,\n",
       " 'decides': 14453,\n",
       " 'episode': 19007,\n",
       " 'per': 43799,\n",
       " 'season': 52195,\n",
       " 'create': 13087,\n",
       " 'usb': 62278,\n",
       " 'keyboard': 31537,\n",
       " 'resembles': 49548,\n",
       " 'touchscreen': 59827,\n",
       " 'phone': 44302,\n",
       " 'he': 25563,\n",
       " 'wanted': 63785,\n",
       " 'country': 12857,\n",
       " 'exchange': 19698,\n",
       " 'cultural': 13600,\n",
       " 'later': 32747,\n",
       " 'child': 10086,\n",
       " 'killed': 31711,\n",
       " 'king': 31771,\n",
       " 'defeated': 14613,\n",
       " 'british': 7707,\n",
       " 'micellar': 36822,\n",
       " 'water': 63916,\n",
       " 'successful': 56897,\n",
       " 'marriage': 35526,\n",
       " 'muslim': 38760,\n",
       " 'christian': 10327,\n",
       " 'know': 31972,\n",
       " 'uber': 60947,\n",
       " 'rate': 48161,\n",
       " 'through': 59156,\n",
       " 'roof': 50559,\n",
       " 'these': 58971,\n",
       " 'mumbai': 38636,\n",
       " 'isnt': 29840,\n",
       " 'demandsupply': 14864,\n",
       " 'too': 59666,\n",
       " 'driver': 17147,\n",
       " 'leading': 32951,\n",
       " 'lower': 34238,\n",
       " 'income': 28257,\n",
       " 'evidence': 19588,\n",
       " 'assad': 3737,\n",
       " 'being': 5633,\n",
       " 'behind': 5622,\n",
       " 'recent': 48484,\n",
       " 'chemical': 9966,\n",
       " 'attack': 4037,\n",
       " 'ghouta': 23329,\n",
       " 'wish': 64855,\n",
       " 'quora': 47639,\n",
       " 'love': 34198,\n",
       " 'much': 38434,\n",
       " 'but': 8260,\n",
       " 'feeling': 20700,\n",
       " 'please': 44892,\n",
       " 'refer': 48806,\n",
       " 'description': 15213,\n",
       " 'current': 13681,\n",
       " 'pay': 43446,\n",
       " 'commission': 11494,\n",
       " 'inhand': 28753,\n",
       " 'salary': 51192,\n",
       " 'newly': 39836,\n",
       " 'airman': 1346,\n",
       " 'facility': 20208,\n",
       " 'blocked': 6730,\n",
       " 'instagram': 28978,\n",
       " 'past': 43271,\n",
       " 'message': 36613,\n",
       " 'worst': 65140,\n",
       " 'chinese': 10138,\n",
       " 'dream': 17082,\n",
       " 'goal': 23702,\n",
       " 'soccer': 54710,\n",
       " 'history': 26318,\n",
       " 'turtle': 60737,\n",
       " 'bite': 6495,\n",
       " 'feel': 20695,\n",
       " 'product': 46415,\n",
       " 'usually': 62360,\n",
       " 'driven': 17146,\n",
       " 'manager': 35116,\n",
       " 'simultaneously': 53910,\n",
       " 'google': 23886,\n",
       " 'okay': 41462,\n",
       " 'trying': 60541,\n",
       " 'fuck': 22319,\n",
       " 'yr': 65789,\n",
       " 'old': 41492,\n",
       " 'son': 54972,\n",
       " 'lived': 33795,\n",
       " 'dick': 15672,\n",
       " 'group': 24397,\n",
       " 'society': 54743,\n",
       " 'generally': 23038,\n",
       " 'favourable': 20579,\n",
       " 'warfare': 63811,\n",
       " 'least': 33003,\n",
       " 'travel': 60165,\n",
       " 'credit': 13114,\n",
       " 'card': 8873,\n",
       " 'fly': 21528,\n",
       " 'visit': 63286,\n",
       " 'website': 64118,\n",
       " 'visual': 63298,\n",
       " 'turn': 60716,\n",
       " 'offs': 41400,\n",
       " 'cant': 8721,\n",
       " 'atheist': 3945,\n",
       " 'richard': 50078,\n",
       " 'dawkins': 14227,\n",
       " 'contribute': 12353,\n",
       " 'more': 38054,\n",
       " 'just': 30904,\n",
       " 'debating': 14369,\n",
       " 'tip': 59385,\n",
       " 'run': 50870,\n",
       " 'morning': 38086,\n",
       " 'effective': 17932,\n",
       " 'somatic': 54934,\n",
       " 'permission': 43925,\n",
       " 'partner': 43201,\n",
       " 'abortion': 162,\n",
       " 'maintain': 34891,\n",
       " 'long': 34035,\n",
       " 'distance': 16406,\n",
       " 'relationship': 49096,\n",
       " 'barrier': 5163,\n",
       " 'learn': 32983,\n",
       " 'understand': 61434,\n",
       " 'continuum': 12312,\n",
       " 'hypothesis': 27329,\n",
       " 'discovered': 16133,\n",
       " 'whenever': 64430,\n",
       " 'warm': 63825,\n",
       " 'cup': 13631,\n",
       " 'milk': 37095,\n",
       " 'microwave': 36944,\n",
       " 'afterwards': 1072,\n",
       " 'sticky': 56203,\n",
       " 'substance': 56834,\n",
       " 'scientific': 51924,\n",
       " 'explanation': 19958,\n",
       " 'phenomenon': 44229,\n",
       " 'personally': 44002,\n",
       " 'chemistry': 9971,\n",
       " 'matter': 35818,\n",
       " 'president': 46095,\n",
       " 'nigeria': 40003,\n",
       " 'situation': 54080,\n",
       " 'gcse': 22952,\n",
       " 'english': 18725,\n",
       " 'im': 27848,\n",
       " 'level': 33289,\n",
       " 'moment': 37795,\n",
       " 'earn': 17605,\n",
       " 'quick': 47561,\n",
       " 'online': 41681,\n",
       " 'system': 57802,\n",
       " 'phd': 44214,\n",
       " 'committed': 11507,\n",
       " 'crime': 13173,\n",
       " 'police': 45129,\n",
       " 'wont': 65001,\n",
       " 'arrest': 3445,\n",
       " 'cooperate': 12478,\n",
       " 'legally': 33090,\n",
       " 'obligated': 41142,\n",
       " 'name': 39050,\n",
       " 'among': 2101,\n",
       " 'novel': 40790,\n",
       " 'protagonist': 46741,\n",
       " 'likely': 33544,\n",
       " 'mexico': 36766,\n",
       " 'war': 63792,\n",
       " 'result': 49718,\n",
       " 'user': 62309,\n",
       " 'owe': 42549,\n",
       " 'completely': 11656,\n",
       " 'upsc': 62145,\n",
       " 'prelim': 45960,\n",
       " 'develop': 15423,\n",
       " 'skill': 54156,\n",
       " 'allows': 1745,\n",
       " 'sleep': 54301,\n",
       " 'wherever': 64449,\n",
       " 'recently': 48485,\n",
       " 'saw': 51656,\n",
       " 'sleeping': 54305,\n",
       " 'her': 25874,\n",
       " 'car': 8820,\n",
       " 'pm': 45003,\n",
       " 'had': 24807,\n",
       " 'sleepover': 54308,\n",
       " 'slept': 54321,\n",
       " 'whole': 64565,\n",
       " 'night': 40007,\n",
       " 'subject': 56736,\n",
       " 'required': 49499,\n",
       " 'biotechnology': 6399,\n",
       " 'adoption': 795,\n",
       " 'metric': 36736,\n",
       " 'officially': 41389,\n",
       " 'kind': 31748,\n",
       " 'mechanical': 36164,\n",
       " 'engineering': 18712,\n",
       " 'rant': 48085,\n",
       " 'seem': 52328,\n",
       " 'paragraph': 43006,\n",
       " 'earth': 17622,\n",
       " 'bob': 6909,\n",
       " 'dylan': 17520,\n",
       " 'become': 5504,\n",
       " 'famous': 20359,\n",
       " 'enough': 18792,\n",
       " 'call': 8514,\n",
       " 'modest': 37673,\n",
       " 'suicide': 57000,\n",
       " 'squad': 55646,\n",
       " 'kid': 31672,\n",
       " 'teenager': 58397,\n",
       " 'top': 59695,\n",
       " 'rank': 48071,\n",
       " 'aiims': 1268,\n",
       " 'aipmt': 1302,\n",
       " 'tom': 59604,\n",
       " 'impeach': 27982,\n",
       " 'dot': 16880,\n",
       " 'com': 11382,\n",
       " 'campaign': 8606,\n",
       " 'john': 30617,\n",
       " 'wesley': 64301,\n",
       " 'hyatt': 27124,\n",
       " 'psychology': 46947,\n",
       " 'riemann': 50132,\n",
       " 'zeta': 65981,\n",
       " 'represented': 49439,\n",
       " 'hyperbola': 27221,\n",
       " 'select': 52385,\n",
       " 'certain': 9550,\n",
       " 'admin': 740,\n",
       " 'access': 308,\n",
       " 'edit': 17855,\n",
       " 'specified': 55290,\n",
       " 'profile': 46456,\n",
       " 'mark': 35462,\n",
       " 'menu': 36501,\n",
       " 'drop': 17174,\n",
       " 'down': 16935,\n",
       " 'ecommerce': 17788,\n",
       " 'germany': 23212,\n",
       " 'solve': 54916,\n",
       " 'problem': 46352,\n",
       " 'agree': 1181,\n",
       " 'via': 62996,\n",
       " 'chat': 9856,\n",
       " 'may': 35899,\n",
       " 'let': 33254,\n",
       " 'emotion': 18468,\n",
       " 'go': 23699,\n",
       " 'extreme': 20100,\n",
       " 'depression': 15135,\n",
       " 'heal': 25603,\n",
       " 'regardless': 48920,\n",
       " 'whether': 64454,\n",
       " 'navigation': 39343,\n",
       " 'choice': 10231,\n",
       " 'offered': 41376,\n",
       " 'app': 2973,\n",
       " 'trouble': 60450,\n",
       " 'having': 25462,\n",
       " 'scientist': 51929,\n",
       " 'determine': 15357,\n",
       " 'designer': 15254,\n",
       " 'opioids': 41810,\n",
       " 'synthesize': 57781,\n",
       " 'blown': 6799,\n",
       " 'smoke': 54502,\n",
       " 'face': 20176,\n",
       " 'happened': 25155,\n",
       " 'werent': 64292,\n",
       " 'gun': 24614,\n",
       " 'invented': 29473,\n",
       " 'earlier': 17595,\n",
       " 'dog': 16680,\n",
       " 'chasing': 9848,\n",
       " 'terrorizing': 58679,\n",
       " 'relieving': 49149,\n",
       " 'yourself': 65761,\n",
       " 'wood': 65005,\n",
       " 'while': 64467,\n",
       " 'hiking': 26160,\n",
       " 'violence': 63206,\n",
       " 'come': 11413,\n",
       " 'iran': 29644,\n",
       " 'obsessively': 41192,\n",
       " 'germanic': 23208,\n",
       " 'ethnic': 19376,\n",
       " 'central': 9489,\n",
       " 'european': 19473,\n",
       " 'continue': 12303,\n",
       " 'nation': 39254,\n",
       " 'colonize': 11332,\n",
       " 'mar': 35358,\n",
       " 'react': 48303,\n",
       " 'clear': 10729,\n",
       " 'illegal': 27791,\n",
       " 'neighbor': 39563,\n",
       " 'tape': 58099,\n",
       " 'own': 42555,\n",
       " 'home': 26479,\n",
       " 'residence': 49578,\n",
       " 'porn': 45385,\n",
       " 'picture': 44492,\n",
       " 'quara': 47481,\n",
       " 'correct': 12647,\n",
       " 'procedure': 46366,\n",
       " 'rating': 48171,\n",
       " 'ride': 50114,\n",
       " 'taken': 57938,\n",
       " 'five': 21219,\n",
       " 'scale': 51709,\n",
       " 'math': 35753,\n",
       " 'language': 32634,\n",
       " 'soul': 55080,\n",
       " 'connection': 12048,\n",
       " 'provide': 46815,\n",
       " 'image': 27852,\n",
       " 'reaction': 48308,\n",
       " 'organic': 41959,\n",
       " 'upgradation': 62093,\n",
       " 'mop': 38023,\n",
       " 'maybe': 35905,\n",
       " 'surrender': 57385,\n",
       " 'seat': 52201,\n",
       " 'hope': 26630,\n",
       " 'second': 52236,\n",
       " 'psychological': 46943,\n",
       " 'leo': 33202,\n",
       " 'zodiac': 66059,\n",
       " 'touristic': 59848,\n",
       " 'spot': 55551,\n",
       " 'falkland': 20305,\n",
       " 'various': 62668,\n",
       " 'step': 56113,\n",
       " 'becoming': 5506,\n",
       " 'entrepreneur': 18894,\n",
       " 'ive': 29996,\n",
       " 'been': 5546,\n",
       " 'boyfriend': 7332,\n",
       " 'over': 42333,\n",
       " 'post': 45491,\n",
       " 'concerned': 11808,\n",
       " 'easy': 17672,\n",
       " 'engaged': 18693,\n",
       " 'italy': 29925,\n",
       " 'church': 10404,\n",
       " 'colon': 11317,\n",
       " 'cleansing': 10727,\n",
       " 'healthy': 25617,\n",
       " 'assume': 3823,\n",
       " 'eclipse': 17768,\n",
       " 'written': 65230,\n",
       " 'ebola': 17714,\n",
       " 'crisis': 13210,\n",
       " 'playing': 44867,\n",
       " 'drum': 17212,\n",
       " 'cover': 12920,\n",
       " 'play': 44848,\n",
       " 'exact': 19634,\n",
       " 'drummer': 17215,\n",
       " 'conjecture': 12017,\n",
       " 'theorem': 58906,\n",
       " 'unprovable': 61852,\n",
       " 'arent': 3279,\n",
       " 'algorithm': 1595,\n",
       " 'asking': 3685,\n",
       " 'cv': 13766,\n",
       " 'raman': 47969,\n",
       " 'humanity': 26979,\n",
       " 'using': 62328,\n",
       " 'nonbiodegradable': 40324,\n",
       " 'plastic': 44813,\n",
       " 'reason': 48400,\n",
       " 'associated': 3812,\n",
       " 'opium': 41811,\n",
       " 'drug': 17207,\n",
       " 'dealer': 14337,\n",
       " 'asia': 3657,\n",
       " 'especially': 19253,\n",
       " 'east': 17651,\n",
       " 'part': 43164,\n",
       " 'kathmandu': 31275,\n",
       " 'serf': 52747,\n",
       " 'delicious': 14811,\n",
       " 'food': 21640,\n",
       " 'building': 8042,\n",
       " 'diverse': 16497,\n",
       " 'inclusive': 28251,\n",
       " 'environment': 18925,\n",
       " 'really': 48367,\n",
       " 'simple': 53878,\n",
       " 'individual': 28448,\n",
       " 'average': 4361,\n",
       " 'package': 42643,\n",
       " 'retail': 49736,\n",
       " 'management': 35114,\n",
       " 'student': 56602,\n",
       " 'middle': 36961,\n",
       " 'reliability': 49137,\n",
       " 'additional': 654,\n",
       " 'task': 58178,\n",
       " 'unique': 61683,\n",
       " 'merchandise': 36524,\n",
       " 'operation': 41789,\n",
       " 'wished': 64858,\n",
       " 'obtain': 41210,\n",
       " 'pr': 45697,\n",
       " 'australia': 4208,\n",
       " 'sponsorship': 55515,\n",
       " 'check': 9914,\n",
       " 'joining': 30631,\n",
       " 'approach': 3075,\n",
       " 'religion': 49151,\n",
       " 'differ': 15748,\n",
       " 'each': 17568,\n",
       " 'wrt': 65244,\n",
       " 'caste': 9104,\n",
       " 'section': 52269,\n",
       " 'etc': 19334,\n",
       " 'accident': 319,\n",
       " 'wasnt': 63886,\n",
       " 'fault': 20555,\n",
       " 'got': 23953,\n",
       " 'blame': 6627,\n",
       " 'gaming': 22696,\n",
       " 'monitor': 37874,\n",
       " 'slim': 54338,\n",
       " ...}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Multinomial Naive Bayes to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MultinomialNB()\n",
    "# model.fit(train, y_train)\n",
    "# print(\"train f1 score:\", metrics.f1_score(y_train,model.predict(train)))\n",
    "# print(\"test f1 score:\", metrics.f1_score(y_test,model.predict(test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sn\n",
    "\n",
    "# # Create the confussion matrix\n",
    "# def plot_confussion_matrix(y_test, y_pred):\n",
    "#     ''' Plot the confussion matrix for the target labels and predictions '''\n",
    "#     cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#     # Create a dataframe with the confussion matrix values\n",
    "#     df_cm = pd.DataFrame(cm, range(cm.shape[0]),\n",
    "#                   range(cm.shape[1]))\n",
    "#     #plt.figure(figsize = (10,7))\n",
    "#     # Plot the confussion matrix\n",
    "#     sn.set(font_scale=1.4) #for label size\n",
    "#     sn.heatmap(df_cm, annot=True,fmt='.0f',annot_kws={\"size\": 10})# font size\n",
    "#     plt.show()\n",
    "\n",
    "# # ROC Curve\n",
    "# # plot no skill\n",
    "# # Calculate the points in the ROC curve\n",
    "# def plot_roc_curve(y_test, y_pred):\n",
    "#     ''' Plot the ROC curve for the target labels and predictions'''\n",
    "#     fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n",
    "#     roc_auc= auc(fpr,tpr)\n",
    "\n",
    "#     plt.title('Receiver Operating Characteristic')\n",
    "#     plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "#     plt.legend(loc = 'lower right')\n",
    "#     plt.plot([0, 1], [0, 1],'r--')\n",
    "#     plt.xlim([0, 1])\n",
    "#     plt.ylim([0, 1])\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predicting the Test set results\n",
    "# y_pred = model.predict(test)\n",
    "\n",
    "# print(metrics.classification_report(y_test, y_pred,  digits=5))\n",
    "# # plot_confussion_matrix(y_test, y_pred)\n",
    "# # plot_roc_curve(y_test, y_pred)\n",
    "\n",
    "# test_y_pred = model.predict(test_df_matrix)\n",
    "# test_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test_DF_TARGET = pd.DataFrame(test_y_pred,columns=['target'])\n",
    "# Test_DF_TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_DF_QID = pd.DataFrame(test_df ,columns=['qid'])\n",
    "# TEST_DF_QID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_DF = pd.concat([TEST_DF_QID, Test_DF_TARGET], axis=1, join='inner')\n",
    "# # TEST_DF = TEST_DF.drop('', axis=1)\n",
    "# # TEST_DF.reset_index(drop=True)\n",
    "# TEST_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_DF.to_csv(\"sample_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Logistic Regression to our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train f1 score:  0.5983304971715036\n",
      "test f1 score:  0.5374478511356864\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=50000,solver=\"lbfgs\")\n",
    "model.fit(train,y_train)\n",
    "y_pred = model.predict(train)\n",
    "print(\"train f1 score: \",f1_score(y_train,y_pred))\n",
    "print(\"test f1 score: \",f1_score(y_test,model.predict(test)))\n",
    "test_y_pred = model.predict(test_df_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_DF_TARGET = pd.DataFrame(test_y_pred,columns=['target'])\n",
    "TEST_DF_QID = pd.DataFrame(test_df ,columns=['qid'])\n",
    "TEST_DF = pd.concat([TEST_DF_QID, Test_DF_TARGET], axis=1, join='inner')\n",
    "# TEST_DF = TEST_DF.drop('', axis=1)\n",
    "# TEST_DF.reset_index(drop=True)\n",
    "TEST_DF.to_csv(\"sample_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying SVM classifier to our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# # Define the parameters to tune\n",
    "# parameters = { \n",
    "#     'C': [1.0, 10],\n",
    "#     'gamma': [1, 'auto', 'scale']\n",
    "# }\n",
    "# # Tune yyperparameters  using Grid Search and a SVM model\n",
    "# model = GridSearchCV(SVC(kernel='rbf'), parameters, cv=5, n_jobs=-1).fit(train, train_df.target)\n",
    "# # model = RandomizedSearchCV(SVC(kernel='rbf'), parameters, cv=5, n_jobs=-1).fit(train, train_df.target)\n",
    "\n",
    "# print(\"train score:\", model.score(train, train_df.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predicting the Test set results\n",
    "# y_pred = model.predict(train)\n",
    "\n",
    "# print(metrics.classification_report(train_df.target, y_pred,  digits=5))\n",
    "# plot_confussion_matrix(train_df.target, y_pred)\n",
    "# plot_roc_curve(train_df.target, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying XG Boost classifier to our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMClassifier\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# def f1_metric(ytrue,preds):\n",
    "#     ''' Return the F1 Score value for the preds and true values, ytrue '''\n",
    "#     return 'f1_score', f1_score((preds>=0.5).astype('int'), ytrue, average='macro'), True\n",
    "\n",
    "# params = {\n",
    "#     'learning_rate': 0.1,\n",
    "#     'n_estimators': 100,\n",
    "#     'colsample_bytree': 0.5,\n",
    "#     'metric': 'f1_score',\n",
    "#     # 'boosting_type':'goss',\n",
    "#     # 'baggeng_freq':1,\n",
    "#     # 'bagging_fraction' : float(0.5),\n",
    "# }\n",
    "\n",
    "# full_clf = LGBMClassifier(**params)\n",
    "\n",
    "# # Fit or train the xgboost model\n",
    "# full_clf.fit(train.astype(np.float32), y_train, eval_set=[(train.astype(np.float32), y_train), (test.astype(np.float32), y_test)],\n",
    "#              verbose=400, eval_metric=f1_metric)\n",
    "# #Show the results\n",
    "# print(\"train f1 score:\", metrics.f1_score(y_train,full_clf.predict(train)))\n",
    "# print(\"test f1 score:\", metrics.f1_score( y_test,full_clf.predict(test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predicting the Test set results\n",
    "# Y_pred = full_clf.predict(test.astype(np.float32))\n",
    "\n",
    "# print(metrics.classification_report(y_test, y_pred,  digits=5))\n",
    "# # plot_confussion_matrix(y_test, y_pred)\n",
    "# # plot_roc_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predicting the Test set results\n",
    "# test_y_pred = full_clf.predict(test_df_matrix.astype(np.float32))\n",
    "\n",
    "# # print(metrics.classification_report(test_df_matrix, test_y_pred,  digits=5))\n",
    "# # plot_confussion_matrix(y_test, y_pred)\n",
    "# # plot_roc_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test_DF_TARGET = pd.DataFrame(test_y_pred,columns=['target'])\n",
    "# Test_DF_TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_DF_QID = pd.DataFrame(test_df ,columns=['qid'])\n",
    "# TEST_DF_QID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_DF = pd.concat([TEST_DF_QID, Test_DF_TARGET], axis=1, join='inner')\n",
    "# # TEST_DF = TEST_DF.drop('', axis=1)\n",
    "# # TEST_DF.reset_index(drop=True)\n",
    "# TEST_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_DF.to_csv(\"sample_submission.csv\",index=False)\n",
    "# TEST_DF.target.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
