{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing important libraries and reading the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Import modules for evaluation purposes\n",
    "# Import libraries for predcton\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,roc_auc_score,roc_curve,auc,f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "train_df = pd.read_csv(\"train_df.csv\")\n",
    "test_df = pd.read_csv(\"test_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for null values, invalid target values and duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df.head(9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.061870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.240919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               target\n",
       "count  1000000.000000\n",
       "mean         0.061870\n",
       "std          0.240919\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid              0\n",
       "question_text    0\n",
       "target           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"target\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.index[train_df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for null values and duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a4f3da3a3df9dd881edd</td>\n",
       "      <td>My period is due on my wedding day. How can I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9914c62ed3f69684d549</td>\n",
       "      <td>How many numbers higher than a million can be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8138ae48649e37091a91</td>\n",
       "      <td>How come I feel nothing for my family, but sti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>981b4753d17ef14d09f7</td>\n",
       "      <td>In case of collapse of the Democratic party, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>452e2c705276ba16b7b7</td>\n",
       "      <td>Who is Émile Naoumoff?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306117</th>\n",
       "      <td>a352dff4fcc2571815ce</td>\n",
       "      <td>Did anyone get an update on Maruti Suzuki All ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306118</th>\n",
       "      <td>ad4a8498d97c536c67b9</td>\n",
       "      <td>What 5 people in history do you find the most ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306119</th>\n",
       "      <td>19784a27b55d4b453fda</td>\n",
       "      <td>How can I remove the tan on my forehead?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306120</th>\n",
       "      <td>370191dba26465997879</td>\n",
       "      <td>If you are a well known hacker, will you be mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306121</th>\n",
       "      <td>8077b4a45cea867d4ff2</td>\n",
       "      <td>If your new enemies be bigger and more dangero...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306122 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "0       a4f3da3a3df9dd881edd   \n",
       "1       9914c62ed3f69684d549   \n",
       "2       8138ae48649e37091a91   \n",
       "3       981b4753d17ef14d09f7   \n",
       "4       452e2c705276ba16b7b7   \n",
       "...                      ...   \n",
       "306117  a352dff4fcc2571815ce   \n",
       "306118  ad4a8498d97c536c67b9   \n",
       "306119  19784a27b55d4b453fda   \n",
       "306120  370191dba26465997879   \n",
       "306121  8077b4a45cea867d4ff2   \n",
       "\n",
       "                                            question_text  \n",
       "0       My period is due on my wedding day. How can I ...  \n",
       "1       How many numbers higher than a million can be ...  \n",
       "2       How come I feel nothing for my family, but sti...  \n",
       "3       In case of collapse of the Democratic party, w...  \n",
       "4                                  Who is Émile Naoumoff?  \n",
       "...                                                   ...  \n",
       "306117  Did anyone get an update on Maruti Suzuki All ...  \n",
       "306118  What 5 people in history do you find the most ...  \n",
       "306119           How can I remove the tan on my forehead?  \n",
       "306120  If you are a well known hacker, will you be mo...  \n",
       "306121  If your new enemies be bigger and more dangero...  \n",
       "\n",
       "[306122 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid              0\n",
       "question_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.index[test_df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the text\n",
    "Common data cleaning steps on all text:\n",
    "\n",
    "1.Make text all lower case\n",
    "\n",
    "2.Remove punctuation\n",
    "\n",
    "3.Remove numerical values\n",
    "\n",
    "4.Remove common non-sensical text (/n)\n",
    "\n",
    "5.Tokenize text\n",
    "\n",
    "6.Remove stop words\n",
    "\n",
    "7.Stemming / lemmatization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here (in round 1) we are doing the following things:-\n",
    "1. Making the text lower case.\n",
    "2. Removing text in square brackets\n",
    "3. Removing punctuation marks from the text\n",
    "4. Removing words containing numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text_round1(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "round1 = lambda x: clean_text_round1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.question_text= train_df.question_text.apply(round1)\n",
    "# train_df.question_text\n",
    "test_df.question_text= test_df.question_text.apply(round1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here (in round2) we are doing:-\n",
    "1. Getting rid of additional punctuation\n",
    "2. Removing some non-sensical text\n",
    "3. Removing urls\n",
    "4. Removing HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a second round of cleaning\n",
    "def clean_text_round2(text):\n",
    "    '''Get rid of some additional punctuation and non-sensical text that was missed the first time around.'''\n",
    "    text = re.sub('[‘’“”…]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub(r\"http\\S+\", '', text)\n",
    "    text = re.sub(re.compile('<.*?>') , '', text)\n",
    "\n",
    "    return text\n",
    "round2 = lambda x: clean_text_round2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         my period is due on my wedding day how can i s...\n",
       "1         how many numbers higher than a million can be ...\n",
       "2         how come i feel nothing for my family but stil...\n",
       "3         in case of collapse of the democratic party wi...\n",
       "4                                     who is émile naoumoff\n",
       "                                ...                        \n",
       "306117    did anyone get an update on maruti suzuki all ...\n",
       "306118    what  people in history do you find the most i...\n",
       "306119              how can i remove the tan on my forehead\n",
       "306120    if you are a well known hacker will you be mor...\n",
       "306121    if your new enemies be bigger and more dangero...\n",
       "Name: question_text, Length: 306122, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.question_text= train_df.question_text.apply(round2)\n",
    "test_df.question_text= test_df.question_text.apply(round2)\n",
    "test_df.question_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.question_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "Tokenization is the process of segmenting running text into sentences and words. In essence, it’s the task of cutting a text into pieces called tokens. \n",
    "$\\newline$ Here we are going to use word tokenizer i.e. the words are the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/karanjitsaha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "def tokenization(text):\n",
    "    return word_tokenize(text)\n",
    "# applying function to the column\n",
    "train_df['question_text']= train_df['question_text'].apply(lambda x: tokenization(x))\n",
    "test_df['question_text']= test_df['question_text'].apply(lambda x: tokenization(x))\n",
    "\n",
    "# train_df.iloc[1].question_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [what, are, interesting, facts, about, microso...\n",
       "1         [what, are, those, things, which, are, not, go...\n",
       "2         [what, should, i, know, to, avoid, being, upso...\n",
       "3          [how, i, add, any, account, with, payment, bank]\n",
       "4         [which, multi, level, marketing, products, are...\n",
       "                                ...                        \n",
       "999995                     [how, is, cse, at, vit, chennai]\n",
       "999996    [how, can, we, prevent, a, holocaust, by, robo...\n",
       "999997    [how, can, i, help, a, student, remember, key,...\n",
       "999998    [what, is, the, difference, between, lace, clo...\n",
       "999999    [what, happens, when, you, look, into, a, brok...\n",
       "Name: question_text, Length: 1000000, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.question_text\n",
    "# import nltk\n",
    "# from nltk.stem import PorterStemmer\n",
    "# ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['question_text'] = train_df['question_text'].apply(lambda x: [ps.stem(y) for y in x]) # Stem every word.\n",
    "# # train_df = train_df.drop(columns=['question_text']) # Get rid of the unstemmed column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a4f3da3a3df9dd881edd</td>\n",
       "      <td>[my, period, is, due, on, my, wedding, day, ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9914c62ed3f69684d549</td>\n",
       "      <td>[how, many, numbers, higher, than, a, million,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8138ae48649e37091a91</td>\n",
       "      <td>[how, come, i, feel, nothing, for, my, family,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>981b4753d17ef14d09f7</td>\n",
       "      <td>[in, case, of, collapse, of, the, democratic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>452e2c705276ba16b7b7</td>\n",
       "      <td>[who, is, émile, naoumoff]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306117</th>\n",
       "      <td>a352dff4fcc2571815ce</td>\n",
       "      <td>[did, anyone, get, an, update, on, maruti, suz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306118</th>\n",
       "      <td>ad4a8498d97c536c67b9</td>\n",
       "      <td>[what, people, in, history, do, you, find, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306119</th>\n",
       "      <td>19784a27b55d4b453fda</td>\n",
       "      <td>[how, can, i, remove, the, tan, on, my, forehead]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306120</th>\n",
       "      <td>370191dba26465997879</td>\n",
       "      <td>[if, you, are, a, well, known, hacker, will, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306121</th>\n",
       "      <td>8077b4a45cea867d4ff2</td>\n",
       "      <td>[if, your, new, enemies, be, bigger, and, more...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306122 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "0       a4f3da3a3df9dd881edd   \n",
       "1       9914c62ed3f69684d549   \n",
       "2       8138ae48649e37091a91   \n",
       "3       981b4753d17ef14d09f7   \n",
       "4       452e2c705276ba16b7b7   \n",
       "...                      ...   \n",
       "306117  a352dff4fcc2571815ce   \n",
       "306118  ad4a8498d97c536c67b9   \n",
       "306119  19784a27b55d4b453fda   \n",
       "306120  370191dba26465997879   \n",
       "306121  8077b4a45cea867d4ff2   \n",
       "\n",
       "                                            question_text  \n",
       "0       [my, period, is, due, on, my, wedding, day, ho...  \n",
       "1       [how, many, numbers, higher, than, a, million,...  \n",
       "2       [how, come, i, feel, nothing, for, my, family,...  \n",
       "3       [in, case, of, collapse, of, the, democratic, ...  \n",
       "4                              [who, is, émile, naoumoff]  \n",
       "...                                                   ...  \n",
       "306117  [did, anyone, get, an, update, on, maruti, suz...  \n",
       "306118  [what, people, in, history, do, you, find, the...  \n",
       "306119  [how, can, i, remove, the, tan, on, my, forehead]  \n",
       "306120  [if, you, are, a, well, known, hacker, will, y...  \n",
       "306121  [if, your, new, enemies, be, bigger, and, more...  \n",
       "\n",
       "[306122 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "Lemmatization is a tool that performs full morphological analysis to more accurately find the root, or “lemma” for a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/karanjitsaha/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/karanjitsaha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dda0b0efc8ba86e81ec4</td>\n",
       "      <td>[what, are, interesting, fact, about, microsof...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dc708b74a108d0fc0ad9</td>\n",
       "      <td>[what, are, those, thing, which, are, not, gon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06a27ec5d82dacd8bfe0</td>\n",
       "      <td>[what, should, i, know, to, avoid, being, upso...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00cbb6b17e3ceb7c5358</td>\n",
       "      <td>[how, i, add, any, account, with, payment, bank]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c304888973a701585a0</td>\n",
       "      <td>[which, multi, level, marketing, product, are,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>4bd96088d0b5f0f2c4f4</td>\n",
       "      <td>[how, is, cse, at, vit, chennai]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>e80edbfc086f7125940f</td>\n",
       "      <td>[how, can, we, prevent, a, holocaust, by, robo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>1506dfad6bd340782a1f</td>\n",
       "      <td>[how, can, i, help, a, student, remember, key,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>b56c60fd407f2f85553c</td>\n",
       "      <td>[what, is, the, difference, between, lace, clo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>a1b32d315c2782cdbcc3</td>\n",
       "      <td>[what, happens, when, you, look, into, a, brok...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "0       dda0b0efc8ba86e81ec4   \n",
       "1       dc708b74a108d0fc0ad9   \n",
       "2       06a27ec5d82dacd8bfe0   \n",
       "3       00cbb6b17e3ceb7c5358   \n",
       "4       7c304888973a701585a0   \n",
       "...                      ...   \n",
       "999995  4bd96088d0b5f0f2c4f4   \n",
       "999996  e80edbfc086f7125940f   \n",
       "999997  1506dfad6bd340782a1f   \n",
       "999998  b56c60fd407f2f85553c   \n",
       "999999  a1b32d315c2782cdbcc3   \n",
       "\n",
       "                                            question_text  target  \n",
       "0       [what, are, interesting, fact, about, microsof...       0  \n",
       "1       [what, are, those, thing, which, are, not, gon...       0  \n",
       "2       [what, should, i, know, to, avoid, being, upso...       0  \n",
       "3        [how, i, add, any, account, with, payment, bank]       0  \n",
       "4       [which, multi, level, marketing, product, are,...       0  \n",
       "...                                                   ...     ...  \n",
       "999995                   [how, is, cse, at, vit, chennai]       0  \n",
       "999996  [how, can, we, prevent, a, holocaust, by, robo...       0  \n",
       "999997  [how, can, i, help, a, student, remember, key,...       0  \n",
       "999998  [what, is, the, difference, between, lace, clo...       0  \n",
       "999999  [what, happens, when, you, look, into, a, brok...       0  \n",
       "\n",
       "[1000000 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "# Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "#defining the object for Lemmatization\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "#defining the function for lemmatization\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text\n",
    "train_df['question_text']=train_df['question_text'].apply(lambda x:lemmatizer(x))\n",
    "test_df['question_text']=test_df['question_text'].apply(lambda x:lemmatizer(x))\n",
    "# train_df.shape\n",
    "train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what',\n",
       " 'are',\n",
       " 'those',\n",
       " 'thing',\n",
       " 'which',\n",
       " 'are',\n",
       " 'not',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'happen',\n",
       " 'ever']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"question_text\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words removal\n",
    "Stop words are commonly occurring words that for some computational processes provide little information or in some cases introduce unnecessary noise and therefore need to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "# # train_df.question_text = [word for word in train_df.question_text if not word in stopwords.words('english')]\n",
    "# # train_df\n",
    "# # print(stopwords.words('english'))\n",
    "# stopwords=stopwords.words('english')\n",
    "# def remove_stopwords(text):\n",
    "#     output= [i for i in text if i not in stopwords]\n",
    "#     return output\n",
    "# #applying the function\n",
    "# train_df['question_text']= train_df['question_text'].apply(lambda x:remove_stopwords(x))\n",
    "# test_df['question_text']= test_df['question_text'].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_stopwords(lemmatizer([\"thing\",\"gonna\",\"happen\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dda0b0efc8ba86e81ec4</td>\n",
       "      <td>[what, are, interesting, fact, about, microsof...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dc708b74a108d0fc0ad9</td>\n",
       "      <td>[what, are, those, thing, which, are, not, gon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06a27ec5d82dacd8bfe0</td>\n",
       "      <td>[what, should, i, know, to, avoid, being, upso...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00cbb6b17e3ceb7c5358</td>\n",
       "      <td>[how, i, add, any, account, with, payment, bank]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c304888973a701585a0</td>\n",
       "      <td>[which, multi, level, marketing, product, are,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>4bd96088d0b5f0f2c4f4</td>\n",
       "      <td>[how, is, cse, at, vit, chennai]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>e80edbfc086f7125940f</td>\n",
       "      <td>[how, can, we, prevent, a, holocaust, by, robo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>1506dfad6bd340782a1f</td>\n",
       "      <td>[how, can, i, help, a, student, remember, key,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>b56c60fd407f2f85553c</td>\n",
       "      <td>[what, is, the, difference, between, lace, clo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>a1b32d315c2782cdbcc3</td>\n",
       "      <td>[what, happens, when, you, look, into, a, brok...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "0       dda0b0efc8ba86e81ec4   \n",
       "1       dc708b74a108d0fc0ad9   \n",
       "2       06a27ec5d82dacd8bfe0   \n",
       "3       00cbb6b17e3ceb7c5358   \n",
       "4       7c304888973a701585a0   \n",
       "...                      ...   \n",
       "999995  4bd96088d0b5f0f2c4f4   \n",
       "999996  e80edbfc086f7125940f   \n",
       "999997  1506dfad6bd340782a1f   \n",
       "999998  b56c60fd407f2f85553c   \n",
       "999999  a1b32d315c2782cdbcc3   \n",
       "\n",
       "                                            question_text  target  \n",
       "0       [what, are, interesting, fact, about, microsof...       0  \n",
       "1       [what, are, those, thing, which, are, not, gon...       0  \n",
       "2       [what, should, i, know, to, avoid, being, upso...       0  \n",
       "3        [how, i, add, any, account, with, payment, bank]       0  \n",
       "4       [which, multi, level, marketing, product, are,...       0  \n",
       "...                                                   ...     ...  \n",
       "999995                   [how, is, cse, at, vit, chennai]       0  \n",
       "999996  [how, can, we, prevent, a, holocaust, by, robo...       0  \n",
       "999997  [how, can, i, help, a, student, remember, key,...       0  \n",
       "999998  [what, is, the, difference, between, lace, clo...       0  \n",
       "999999  [what, happens, when, you, look, into, a, brok...       0  \n",
       "\n",
       "[1000000 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         what are interesting fact about microsoft history\n",
      "1         what are those thing which are not gon na happ...\n",
      "2         what should i know to avoid being upsold when ...\n",
      "3                   how i add any account with payment bank\n",
      "4         which multi level marketing product are actual...\n",
      "                                ...                        \n",
      "999995                            how is cse at vit chennai\n",
      "999996    how can we prevent a holocaust by robot ai or ...\n",
      "999997    how can i help a student remember key step and...\n",
      "999998    what is the difference between lace closure la...\n",
      "999999      what happens when you look into a broken mirror\n",
      "Name: question_text, Length: 1000000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def makeSentence(text):\n",
    "    return ' '.join(list(text))\n",
    "\n",
    "train_df.question_text = train_df['question_text'].apply(lambda x: makeSentence(x))\n",
    "test_df.question_text = test_df['question_text'].apply(lambda x: makeSentence(x))\n",
    "\n",
    "print(train_df.question_text)\n",
    "# print(makeSentence(train_df.question_text[0]))\n",
    "# ' '.join(list(train_df.question_text)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing train test split of the train_df.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df.question_text, train_df.target.values , test_size=0.15)\n",
    "X_train.shape\n",
    "\n",
    "test_x = test_df.question_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306122, 161849)\n",
      "(850000, 161849)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tfidf = CountVectorizer()\n",
    "# Numericalize the train dataset\n",
    "train = tfidf.fit_transform(X_train.values.astype('U'))\n",
    "# Numericalize the test dataset\n",
    "test = tfidf.transform(X_test.values.astype('U'))\n",
    "\n",
    "# for test_df\n",
    "test_df_matrix = tfidf.transform(test_x.values.astype('U'))\n",
    "print(test_df_matrix.shape)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Multinomial Naive Bayes to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train f1 score: 0.5801998068428302\n",
      "test f1 score: 0.5678815703176239\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97    797249\n",
      "           1       0.50      0.69      0.58     52751\n",
      "\n",
      "    accuracy                           0.94    850000\n",
      "   macro avg       0.74      0.82      0.77    850000\n",
      "weighted avg       0.95      0.94      0.94    850000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(train, y_train)\n",
    "print(\"train f1 score:\", metrics.f1_score(y_train,model.predict(train)))\n",
    "print(\"test f1 score:\", metrics.f1_score(y_test,model.predict(test)))\n",
    "print(metrics.classification_report(y_train,model.predict(train)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sn\n",
    "\n",
    "# # Create the confussion matrix\n",
    "# def plot_confussion_matrix(y_test, y_pred):\n",
    "#     ''' Plot the confussion matrix for the target labels and predictions '''\n",
    "#     cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#     # Create a dataframe with the confussion matrix values\n",
    "#     df_cm = pd.DataFrame(cm, range(cm.shape[0]),\n",
    "#                   range(cm.shape[1]))\n",
    "#     #plt.figure(figsize = (10,7))\n",
    "#     # Plot the confussion matrix\n",
    "#     sn.set(font_scale=1.4) #for label size\n",
    "#     sn.heatmap(df_cm, annot=True,fmt='.0f',annot_kws={\"size\": 10})# font size\n",
    "#     plt.show()\n",
    "\n",
    "# # ROC Curve\n",
    "# # plot no skill\n",
    "# # Calculate the points in the ROC curve\n",
    "# def plot_roc_curve(y_test, y_pred):\n",
    "#     ''' Plot the ROC curve for the target labels and predictions'''\n",
    "#     fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n",
    "#     roc_auc= auc(fpr,tpr)\n",
    "\n",
    "#     plt.title('Receiver Operating Characteristic')\n",
    "#     plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "#     plt.legend(loc = 'lower right')\n",
    "#     plt.plot([0, 1], [0, 1],'r--')\n",
    "#     plt.xlim([0, 1])\n",
    "#     plt.ylim([0, 1])\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predicting the Test set results\n",
    "# y_pred = model.predict(test)\n",
    "\n",
    "# print(metrics.classification_report(y_test, y_pred,  digits=5))\n",
    "# # plot_confussion_matrix(y_test, y_pred)\n",
    "# # plot_roc_curve(y_test, y_pred)\n",
    "\n",
    "# test_y_pred = model.predict(test_df_matrix)\n",
    "# test_y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Logistic Regression to our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train f1 score:  0.6088470038589701\n",
      "test f1 score:  0.537865633765193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98    797249\n",
      "           1       0.77      0.50      0.61     52751\n",
      "\n",
      "    accuracy                           0.96    850000\n",
      "   macro avg       0.87      0.75      0.79    850000\n",
      "weighted avg       0.96      0.96      0.96    850000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=50000,solver=\"lbfgs\")\n",
    "model.fit(train,y_train)\n",
    "y_pred = model.predict(train)\n",
    "print(\"train f1 score: \",f1_score(y_train,y_pred))\n",
    "print(\"test f1 score: \",f1_score(y_test,model.predict(test)))\n",
    "test_y_pred = model.predict(test_df_matrix)\n",
    "print(metrics.classification_report(y_train,y_pred) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying SVM classifier to our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# # Define the parameters to tune\n",
    "# parameters = { \n",
    "#     'C': [1.0, 10],\n",
    "#     'gamma': [1, 'auto', 'scale']\n",
    "# }\n",
    "# # Tune yyperparameters  using Grid Search and a SVM model\n",
    "# model = GridSearchCV(SVC(kernel='rbf'), parameters, cv=5, n_jobs=-1).fit(train, train_df.target)\n",
    "# # model = RandomizedSearchCV(SVC(kernel='rbf'), parameters, cv=5, n_jobs=-1).fit(train, train_df.target)\n",
    "\n",
    "# print(\"train score:\", model.score(train, train_df.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predicting the Test set results\n",
    "# y_pred = model.predict(train)\n",
    "\n",
    "# print(metrics.classification_report(train_df.target, y_pred,  digits=5))\n",
    "# plot_confussion_matrix(train_df.target, y_pred)\n",
    "# plot_roc_curve(train_df.target, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying XG Boost classifier to our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMClassifier\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# def f1_metric(ytrue,preds):\n",
    "#     ''' Return the F1 Score value for the preds and true values, ytrue '''\n",
    "#     return 'f1_score', f1_score((preds>=0.5).astype('int'), ytrue, average='macro'), True\n",
    "\n",
    "# params = {\n",
    "#     'learning_rate': 0.1,\n",
    "#     'n_estimators': 100,\n",
    "#     'colsample_bytree': 0.5,\n",
    "#     'metric': 'f1_score',\n",
    "#     # 'boosting_type':'goss',\n",
    "#     # 'baggeng_freq':1,\n",
    "#     # 'bagging_fraction' : float(0.5),\n",
    "# }\n",
    "\n",
    "# full_clf = LGBMClassifier(**params)\n",
    "\n",
    "# # Fit or train the xgboost model\n",
    "# full_clf.fit(train.astype(np.float32), y_train, eval_set=[(train.astype(np.float32), y_train), (test.astype(np.float32), y_test)],\n",
    "#              verbose=400, eval_metric=f1_metric)\n",
    "# #Show the results\n",
    "# print(\"train f1 score:\", metrics.f1_score(y_train,full_clf.predict(train)))\n",
    "# print(\"test f1 score:\", metrics.f1_score( y_test,full_clf.predict(test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predicting the Test set results\n",
    "# Y_pred = full_clf.predict(test.astype(np.float32))\n",
    "\n",
    "# print(metrics.classification_report(y_test, y_pred,  digits=5))\n",
    "# # plot_confussion_matrix(y_test, y_pred)\n",
    "# # plot_roc_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predicting the Test set results\n",
    "# test_y_pred = full_clf.predict(test_df_matrix.astype(np.float32))\n",
    "\n",
    "# # print(metrics.classification_report(test_df_matrix, test_y_pred,  digits=5))\n",
    "# # plot_confussion_matrix(y_test, y_pred)\n",
    "# # plot_roc_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying XGBoost Classifier to our dataset using xgboost library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb_cl = xgb.XGBClassifier(objective=\"binary:logistic\" )\n",
    "xgb_cl.fit(train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = {\n",
    "#     \"max_depth\": [3, 4, 5, 7],\n",
    "#     \"learning_rate\": [0.1, 0.01, 0.05],\n",
    "#     \"gamma\": [0, 0.25, 1],\n",
    "#     \"reg_lambda\": [0, 1, 10],\n",
    "#     # \"scale_pos_weight\": [1, 3, 5],\n",
    "#     \"subsample\": [0.8],\n",
    "#     \"colsample_bytree\": [0.5],\n",
    "# }\n",
    "# grid_cv = GridSearchCV(xgb_cl, param_grid, n_jobs=-1, cv=3, scoring=\"roc_auc\")\n",
    "# grid_cv.fit(train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train f1 score: \",metrics.f1_score(y_train,grid_cv.predict(train)))\n",
    "print(\"test f1 score: \",metrics.f1_score(y_test,grid_cv.predict(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_y_pred = xgb_cl.predict(test_df_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model and its parameters using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0 0 0 ... 0 0 0].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [43], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39m# Use the loaded pickled model to make predictions\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# knn_from_pickle.predict(X_test)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model_from_pickle\u001b[39m.\u001b[39mfit(train,y_train)\n\u001b[0;32m---> 12\u001b[0m \u001b[39mprint\u001b[39m(metrics\u001b[39m.\u001b[39mclassification_report(y_train,model_from_pickle\u001b[39m.\u001b[39mpredict(y_train)) )\n\u001b[1;32m     13\u001b[0m model_from_pickle\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_base.py:447\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    434\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m    Predict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[39m        Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m     scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[1;32m    448\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(scores\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    449\u001b[0m         indices \u001b[39m=\u001b[39m (scores \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_base.py:429\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[39mPredict confidence scores for samples.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39m    this class would be predicted.\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    427\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 429\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    430\u001b[0m scores \u001b[39m=\u001b[39m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n\u001b[1;32m    431\u001b[0m \u001b[39mreturn\u001b[39;00m scores\u001b[39m.\u001b[39mravel() \u001b[39mif\u001b[39;00m scores\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    878\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 879\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    880\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    881\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    884\u001b[0m         )\n\u001b[1;32m    886\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    887\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    888\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    889\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    890\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0 0 0 ... 0 0 0].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "  \n",
    "# Save the trained model as a pickle string.\n",
    "saved_model = pickle.dumps(model)\n",
    "  \n",
    "# Load the pickled model\n",
    "model_from_pickle = pickle.loads(saved_model)\n",
    "  \n",
    "# Use the loaded pickled model to make predictions\n",
    "# knn_from_pickle.predict(X_test)\n",
    "model_from_pickle.fit(train,y_train)\n",
    "print(metrics.classification_report(y_train,model_from_pickle.predict(train)) )\n",
    "model_from_pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test_DF_TARGET = pd.DataFrame(test_y_pred,columns=['target'])\n",
    "# TEST_DF_QID = pd.DataFrame(test_df ,columns=['qid'])\n",
    "# TEST_DF = pd.concat([TEST_DF_QID, Test_DF_TARGET], axis=1, join='inner')\n",
    "# TEST_DF.to_csv(\"sample_submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
